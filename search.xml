<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>分布式计算学习笔记(四) Ray 实战 -- 将CNN网络改写成 Ray</title>
      <link href="/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%9B%9B-Ray%20%E5%AE%9E%E6%88%98%20--%20%E5%B0%86CNN%E7%BD%91%E7%BB%9C%E6%94%B9%E5%86%99%E6%88%90%20Ray.html"/>
      <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%9B%9B-Ray%20%E5%AE%9E%E6%88%98%20--%20%E5%B0%86CNN%E7%BD%91%E7%BB%9C%E6%94%B9%E5%86%99%E6%88%90%20Ray.html</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本篇博客首先会对 CNN + MNIST 的神经网络结构进行分析（因为我也不会），之后利用 Ray 的 API进行改写，完成分布式框架上的深度学习工作。</p><a id="more"></a><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="CNN-结构"><a href="#CNN-结构" class="headerlink" title="CNN 结构"></a>CNN 结构</h2><h3 id="tf-reshape-tensor-shape-name-None"><a href="#tf-reshape-tensor-shape-name-None" class="headerlink" title="tf.reshape(tensor, shape, name=None)"></a>tf.reshape(tensor, shape, name=None)</h3><p>将 tensor 变换为参数shape的形式</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">xs &#x3D; tf.placeholder(tf.float32, [None,784])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">x_image &#x3D; &#x3D;tf.reshape(xs,[-1,28,28,1])</span></pre></td></tr></table></figure><p>其中，两个28表示了该图片的长宽是28个像素，厚度因为是黑白图片，所以为1，如果图片是rgb颜色，则为3，最开始的-1表示这种图片的多少，即 <code>x_image[0]</code> 为一张完整的图片。</p><h3 id="tf-nn-conv2d-input-filter-strides-padding-use-cudnn-on-gpu-None-data-format-None-name-None"><a href="#tf-nn-conv2d-input-filter-strides-padding-use-cudnn-on-gpu-None-data-format-None-name-None" class="headerlink" title="tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)"></a>tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)</h3><p>卷积操作，filter= patch(筛选器)<br><code>input</code> : <code>[batch, in_height, in_width, in_channels]</code><br><code>filter</code>: <code>[filter_height, filter_width, in_channels, out_channels]</code><br>其中 <code>in_cahnnels</code>代表的是图像的高度，输入为1，由于卷积操作之后图像的高度会变高，所以<code>out_cahnnels</code>要大于<code>in_channels</code>的值<br><code>strides</code>: <code>[1, x_movement, y_movement, 1]</code> 第一个参数和第四个参数都是1，第二个和第三个是 x 轴和 y 轴的移动距离，如果都是2，代表着每次移动2个像素（会有一个像素的信息不能被采集）<br><code>padding</code>: 当<code>padding=SAME</code> 时，输入与输出形状相同</p><h3 id="tf-nn-max-pool-value-ksize-strides-padding-name-None"><a href="#tf-nn-max-pool-value-ksize-strides-padding-name-None" class="headerlink" title="tf.nn.max_pool(value, ksize, strides, padding, name=None)"></a>tf.nn.max_pool(value, ksize, strides, padding, name=None)</h3><p>池化操作<br><code>value</code>: <code>[batch, in_height, in_width, in_channels]</code>池化输入参数<br><code>ksize</code>:  <code>[1, height, width, 1]</code> 池化窗口大小<br><code>strides` = `[1, x_movement, y_movement, 1]</code> 第一个参数和第四个参数都是1，第二个和第三个是x轴和y轴的移动距离，如果都是2，代表着每次移动2个像素（会有一个像素的信息不能被采集）<br><code>padding</code>: 当 <code>padding=SAME</code> 时，输入与输出形状相同</p><h3 id="基于-MNIST-的图像分类结构"><a href="#基于-MNIST-的图像分类结构" class="headerlink" title="基于 MNIST 的图像分类结构"></a>基于 MNIST 的图像分类结构</h3><p><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/cnn-str.jpeg" alt></p><h2 id="CNN-MNIST"><a href="#CNN-MNIST" class="headerlink" title="CNN + MNIST"></a>CNN + MNIST</h2><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> tensorflow.compat.v1 <span class="hljs-keyword">as</span> tf</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">tf.disable_v2_behavior()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> time</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># number 1 to 10 data</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(<span class="hljs-string">'MNIST_data'</span>, one_hot=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_accuracy</span><span class="hljs-params">(v_xs, v_ys)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># global prediction</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs, keep_prob: <span class="hljs-number">1</span>&#125;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    correct_prediction = tf.equal(tf.argmax(y_pre, <span class="hljs-number">1</span>), tf.argmax(v_ys, <span class="hljs-number">1</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys, keep_prob: <span class="hljs-number">1</span>&#125;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> result</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weight_variable</span><span class="hljs-params">(shape)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="hljs-number">0.1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.Variable(initial)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bias_variable</span><span class="hljs-params">(shape)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">    initial = tf.constant(<span class="hljs-number">0.1</span>, shape=shape)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.Variable(initial)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">conv2d</span><span class="hljs-params">(x, W)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># stride [1, x_movement, y_movement, 1]</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># Must have strides[0] = strides[3] = 1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">max_pool_2x2</span><span class="hljs-params">(x)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># stride [1, x_movement, y_movement, 1]</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># define placeholder for inputs to network</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line">xs = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">784</span>])  <span class="hljs-comment"># 28x28</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line">ys = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">10</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line">keep_prob = tf.placeholder(tf.float32)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line">x_image = tf.reshape(xs,[<span class="hljs-number">-1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">## conv1 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line">W_conv1 = weight_variable([<span class="hljs-number">5</span>,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">32</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line">b_conv1 = bias_variable([<span class="hljs-number">32</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) <span class="hljs-comment"># x_image: 28*28*1 output size: 28*28*32</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line">h_pool1 = max_pool_2x2(h_conv1) <span class="hljs-comment"># output size: 14*14*32</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">## conv2 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line">W_conv2 = weight_variable([<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">32</span>, <span class="hljs-number">64</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line">b_conv2 = bias_variable([<span class="hljs-number">64</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">50</span></pre></td><td class="code"><pre><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)<span class="hljs-comment"># 14*14*32 -&gt; 14*14*64</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">51</span></pre></td><td class="code"><pre><span class="line">h_pool2 = max_pool_2x2(h_conv2) <span class="hljs-comment"># 14*14*64 -&gt; 7*7*64</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">52</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">53</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">## func1 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">54</span></pre></td><td class="code"><pre><span class="line">W_fc1 = weight_variable([<span class="hljs-number">7</span>*<span class="hljs-number">7</span>*<span class="hljs-number">64</span>,<span class="hljs-number">1024</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">55</span></pre></td><td class="code"><pre><span class="line">b_fc1 = bias_variable([<span class="hljs-number">1024</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">56</span></pre></td><td class="code"><pre><span class="line">h_pool2_flat = tf.reshape(h_pool2,[<span class="hljs-number">-1</span>, <span class="hljs-number">7</span>*<span class="hljs-number">7</span>*<span class="hljs-number">64</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">57</span></pre></td><td class="code"><pre><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">58</span></pre></td><td class="code"><pre><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">59</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">60</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">## func2 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">61</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">62</span></pre></td><td class="code"><pre><span class="line">W_fc2 = weight_variable([<span class="hljs-number">1024</span>, <span class="hljs-number">10</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">63</span></pre></td><td class="code"><pre><span class="line">b_fc2 = bias_variable([<span class="hljs-number">10</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">64</span></pre></td><td class="code"><pre><span class="line">prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">65</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">66</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># the error between prediction and real data</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">67</span></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">68</span></pre></td><td class="code"><pre><span class="line">                                              reduction_indices=[<span class="hljs-number">1</span>]))       <span class="hljs-comment"># loss</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">69</span></pre></td><td class="code"><pre><span class="line">train_step = tf.train.AdamOptimizer(<span class="hljs-number">1e-4</span>).minimize(cross_entropy)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">70</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">71</span></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">72</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># important step</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">73</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># tf.initialize_all_variables() no long valid from</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">74</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 2017-03-02 if using tensorflow &gt;= 0.12</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">75</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">if</span> int((tf.__version__).split(<span class="hljs-string">'.'</span>)[<span class="hljs-number">1</span>]) &lt; <span class="hljs-number">12</span> <span class="hljs-keyword">and</span> int((tf.__version__).split(<span class="hljs-string">'.'</span>)[<span class="hljs-number">0</span>]) &lt; <span class="hljs-number">1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">76</span></pre></td><td class="code"><pre><span class="line">    init = tf.initialize_all_variables()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">77</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">78</span></pre></td><td class="code"><pre><span class="line">    init = tf.global_variables_initializer()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">79</span></pre></td><td class="code"><pre><span class="line">sess.run(init)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">80</span></pre></td><td class="code"><pre><span class="line">start = time.time()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">81</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">82</span></pre></td><td class="code"><pre><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="hljs-number">100</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">83</span></pre></td><td class="code"><pre><span class="line">    sess.run(train_step, feed_dict=&#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">84</span></pre></td><td class="code"><pre><span class="line">             xs: batch_xs, ys: batch_ys, keep_prob: <span class="hljs-number">0.5</span>&#125;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">85</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">86</span></pre></td><td class="code"><pre><span class="line">        print(compute_accuracy(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">87</span></pre></td><td class="code"><pre><span class="line">            mnist.test.images[:<span class="hljs-number">1000</span>], mnist.test.labels[:<span class="hljs-number">1000</span>]))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">88</span></pre></td><td class="code"><pre><span class="line">end = time.time()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">89</span></pre></td><td class="code"><pre><span class="line">print(<span class="hljs-string">'execution time: '</span> + str(end-start) + <span class="hljs-string">'s'</span>)</span></pre></td></tr></table></figure><h2 id="CNN-Ray"><a href="#CNN-Ray" class="headerlink" title="CNN + Ray"></a>CNN + Ray</h2><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> os</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> ray</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> time</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> tensorflow.compat.v1 <span class="hljs-keyword">as</span> tf</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">tf.disable_v2_behavior()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">ray.init(num_gpus=<span class="hljs-number">8</span>, include_webui=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># consruct neural network</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weight_variable</span><span class="hljs-params">(shape)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="hljs-number">0.1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.Variable(initial)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bias_variable</span><span class="hljs-params">(shape)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    initial = tf.constant(<span class="hljs-number">0.1</span>, shape=shape)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.Variable(initial)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">conv2d</span><span class="hljs-params">(x, W)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># stride [1, x_movement, y_movement, 1]</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># Must have strides[0] = strides[3] = 1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">max_pool_2x2</span><span class="hljs-params">(x)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># stride [1, x_movement, y_movement, 1]</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">'SAME'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">construct_network</span><span class="hljs-params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># define placeholder for inputs to network</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line">    xs = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">784</span>])  <span class="hljs-comment"># 28x28</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line">    ys = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">10</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line">    keep_prob = tf.placeholder(tf.float32)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line">    x_image = tf.reshape(xs, [<span class="hljs-number">-1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment">## conv1 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line">    W_conv1 = weight_variable([<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">32</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line">    b_conv1 = bias_variable([<span class="hljs-number">32</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># x_image: 28*28*1 output size: 28*28*32</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line">    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line">    h_pool1 = max_pool_2x2(h_conv1)  <span class="hljs-comment"># output size: 14*14*32</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment">## conv2 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line">    W_conv2 = weight_variable([<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">32</span>, <span class="hljs-number">64</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line">    b_conv2 = bias_variable([<span class="hljs-number">64</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) +</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line">                         b_conv2)  <span class="hljs-comment"># 14*14*32 -&gt; 14*14*64</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line">    h_pool2 = max_pool_2x2(h_conv2)  <span class="hljs-comment"># 14*14*64 -&gt; 7*7*64</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">50</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">51</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment">## func1 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">52</span></pre></td><td class="code"><pre><span class="line">    W_fc1 = weight_variable([<span class="hljs-number">7</span>*<span class="hljs-number">7</span>*<span class="hljs-number">64</span>, <span class="hljs-number">1024</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">53</span></pre></td><td class="code"><pre><span class="line">    b_fc1 = bias_variable([<span class="hljs-number">1024</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">54</span></pre></td><td class="code"><pre><span class="line">    h_pool2_flat = tf.reshape(h_pool2, [<span class="hljs-number">-1</span>, <span class="hljs-number">7</span>*<span class="hljs-number">7</span>*<span class="hljs-number">64</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">55</span></pre></td><td class="code"><pre><span class="line">    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">56</span></pre></td><td class="code"><pre><span class="line">    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">57</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">58</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment">## func2 layer ##</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">59</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">60</span></pre></td><td class="code"><pre><span class="line">    W_fc2 = weight_variable([<span class="hljs-number">1024</span>, <span class="hljs-number">10</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">61</span></pre></td><td class="code"><pre><span class="line">    b_fc2 = bias_variable([<span class="hljs-number">10</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">62</span></pre></td><td class="code"><pre><span class="line">    prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">63</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">64</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># the error between prediction and real data</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">65</span></pre></td><td class="code"><pre><span class="line">    cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">66</span></pre></td><td class="code"><pre><span class="line">                                                  reduction_indices=[<span class="hljs-number">1</span>]))       <span class="hljs-comment"># loss</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">67</span></pre></td><td class="code"><pre><span class="line">    train_step = tf.train.AdamOptimizer(<span class="hljs-number">1e-4</span>).minimize(cross_entropy)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">68</span></pre></td><td class="code"><pre><span class="line">    </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">69</span></pre></td><td class="code"><pre><span class="line">    correct_prediction = tf.equal(tf.argmax(prediction, <span class="hljs-number">1</span>), tf.argmax(ys, <span class="hljs-number">1</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">70</span></pre></td><td class="code"><pre><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">71</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">72</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> xs, ys, train_step, keep_prob, accuracy</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">73</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">74</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote(num_gpus=1)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">75</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CNN_ON_RAY</span><span class="hljs-params">(object)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">76</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, mnist_data)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">77</span></pre></td><td class="code"><pre><span class="line">        self.mnist = mnist_data</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">78</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-comment"># Set an environment variable to tell TensorFlow which GPUs to use. Note</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">79</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-comment"># that this must be done before the call to tf.Session.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">80</span></pre></td><td class="code"><pre><span class="line">        os.environ[<span class="hljs-string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="hljs-string">","</span>.join(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">81</span></pre></td><td class="code"><pre><span class="line">            [str(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ray.get_gpu_ids()])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">82</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">with</span> tf.Graph().as_default():</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">83</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">"/gpu:0"</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">84</span></pre></td><td class="code"><pre><span class="line">                self.xs, self.ys, self.train_step, self.keep_prob, self.accuracy = construct_network()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">85</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># Allow this to run on CPUs if there aren't any GPUs.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">86</span></pre></td><td class="code"><pre><span class="line">                config = tf.ConfigProto(allow_soft_placement=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">87</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment">#### normal network</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">88</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># init = tf.initialize_all_variables()</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">89</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># sess = tf.Session()</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">90</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># sess.run(init)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">91</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment">####</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">92</span></pre></td><td class="code"><pre><span class="line">                self.sess = tf.Session(config=config)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">93</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># Initialize the network.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">94</span></pre></td><td class="code"><pre><span class="line">                init = tf.global_variables_initializer()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">95</span></pre></td><td class="code"><pre><span class="line">                self.sess.run(init)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">96</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">97</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(self, num_steps)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">98</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_steps):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">99</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-comment"># load dataset by batch</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">100</span></pre></td><td class="code"><pre><span class="line">            batch_xs, batch_ys = self.mnist.train.next_batch(<span class="hljs-number">100</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">101</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-comment"># train</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">102</span></pre></td><td class="code"><pre><span class="line">            self.sess.run(self.train_step, feed_dict=&#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">103</span></pre></td><td class="code"><pre><span class="line">                          self.xs: batch_xs, self.ys: batch_ys, self.keep_prob: <span class="hljs-number">0.5</span>&#125;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">104</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">105</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">106</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># print(compute_accuracy(</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">107</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment">#     mnist.test.images[:1000], mnist.test.labels[:1000]))</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">108</span></pre></td><td class="code"><pre><span class="line">                print(self.get_accuracy())</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">109</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">110</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_accuracy</span><span class="hljs-params">(self)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">111</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span> self.sess.run(self.accuracy, feed_dict=&#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">112</span></pre></td><td class="code"><pre><span class="line">            self.xs: mnist.test.images[:<span class="hljs-number">1000</span>], self.ys: mnist.test.labels[:<span class="hljs-number">1000</span>], self.keep_prob: <span class="hljs-number">1</span>&#125;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">113</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">114</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># load MNIST dataset，并告诉Ray如何序列化定制类。</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">115</span></pre></td><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(<span class="hljs-string">"MNIST_data"</span>, one_hot=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">116</span></pre></td><td class="code"><pre><span class="line">start = time.time()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">117</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Create the actor. 实例化actor并运行构造函数</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">118</span></pre></td><td class="code"><pre><span class="line">nn = CNN_ON_RAY.remote(mnist)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">119</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">120</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Run a few steps of training and print the accuracy.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">121</span></pre></td><td class="code"><pre><span class="line">train_id = nn.train.remote(<span class="hljs-number">1000</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">122</span></pre></td><td class="code"><pre><span class="line">ray.get(train_id)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">123</span></pre></td><td class="code"><pre><span class="line">end = time.time()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">124</span></pre></td><td class="code"><pre><span class="line">print(<span class="hljs-string">'execution time: '</span> + str(end-start) + <span class="hljs-string">'s'</span>)</span></pre></td></tr></table></figure><h2 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h2><h2 id="No-Ray"><a href="#No-Ray" class="headerlink" title="No Ray"></a>No Ray</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">0.087</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">0.749</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">0.854</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">0.887</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">0.902</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">0.926</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">0.919</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">0.941</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">0.946</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">0.949</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">0.954</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">0.953</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">0.958</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">0.956</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">0.96</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">0.965</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">0.962</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">0.963</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">0.965</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">0.968</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">execution time: 52.58758211135864s</span></pre></td></tr></table></figure><h2 id="Ray"><a href="#Ray" class="headerlink" title="Ray"></a>Ray</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.077</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.722</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.853</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.877</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.904</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.912</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.921</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.932</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.94</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.938</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.944</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.941</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.944</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.952</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.953</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.951</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.957</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.959</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.958</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;11597) 0.966</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">execution time: 59.315696001052856s</span></pre></td></tr></table></figure><p>从结果看，Ray在性能上没有进步太多，这是因为在运行过程中并没有使用多 worker，也就是没有发挥 Ray 本身（分布式框架）的属性。因为是前期实验，所以没有太多更复杂的操作，多worker并行操作就需要涉及到不同worker之间 weight, bias的同步以及网络结构的统一，这都是需要在后期考虑的事情。<br><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-dashboard.png" alt="dashboard"></p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>通过和同学的讨论，之后会选择在终端先启动 Ray，然后在 ray.init() 中进行调用的方式进行训练，这样就避免了每一次任务结束之后 Ray 会自动关闭的情况，但在测试中发现了一些问题，进行记录。</p><ol><li><p>在终端中启动 Ray 之后，会进行一下输出 </p><pre><code>Started Ray on this node. You can add additional nodes to the cluster by callingray start --address=&apos;172.17.78.111:21907&apos; --redis-password=&apos;5241590000000000&apos;</code></pre><p> 其意思为增加新的节点，在测试过程中我一共输入了两遍，逻辑上共创建了1个母节点（master）和两个子节点（slave），但在 dashboard输出中，我并没有看到3个节点间的逻辑关系<br> <img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-test1.png" alt="ray-test1"><br> <img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-test2.png" alt="ray-test2"></p></li><li><p>终端运行 <code>python3 cnn-ray.py</code> , 在 dashboard 中可以看到，的确只有一个进程（worker）在执行task。<br> <img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-test3.png" alt="ray-test3"><br> 但是在终端输出界面，却发现了同样的结果输出了3次的情况<br> <img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-test4.png" alt="ray-test4"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Distributed System </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>82 年生的金智英</title>
      <link href="/82%20%E5%B9%B4%E7%94%9F%E7%9A%84%E9%87%91%E6%99%BA%E8%8B%B1.html"/>
      <url>/82%20%E5%B9%B4%E7%94%9F%E7%9A%84%E9%87%91%E6%99%BA%E8%8B%B1.html</url>
      
        <content type="html"><![CDATA[<p>这个社会看似改变了很多，可是仔细窥探内部细则和约定俗成，便会发现其实还是固守着旧习，所以就结果而论，应该说这个社会根本没有改变。</p><a id="more"></a><p>前几天想着从豆瓣上淘点书，一本一本点开查看简介，实在是有点疲惫于那些励志向上的书籍，恰巧翻到了这本讲女性主义的韩国作家的书，抛去各种称赞推荐的tag，书的主题着实吸引到了我。书的内容不多，整体文笔也挺平滑，无太多出彩之处，但也就是太反映社会了，才被大家所推崇吧。全篇围绕着金智英，从她的小时候，一直描写到了生完小孩得抑郁症结束。总感觉，她是把亚洲女性从小到大说经历的种种不平等经历都汇总起来，将女主人公的心里描写和动作真真切切的展现在读者面前，估计很多男生打低分的原因是因为这些苦难在他们眼里根本不值得一提，而那些打高分的往往是感同身受的女性群体，或许在阅读过程中，她们能产生某种神秘的共鸣 - 这种共鸣存在于女性社会长达数十年之久。</p><p>金智英的母亲为了养活自己的哥哥弟弟上学，辍学在家种田，去城市打工赚钱，穷尽一生完成了她的父母的愿望，而自己却失去了生活，梦想，朋友。后知后觉的她并不想过多的影响金智英，在饭桌上，母亲不会因为她提前于弟弟吃饭而骂她，给了金智英更好的生活和希望。虽然金智英幼年时期会受到同学的欺负，老师的不信任，但她都咬咬牙，忍气吞声的过去了，结束学生时代的她本可以安安稳稳追求梦想，却因为金融危机而面临没有工作的危机，四处求职，甚至在职场面试上遭遇他人的骚扰，而这一次，金智英再次选择了回避。结婚怀孕之后，本想着维持工作的她挤在地铁里，年轻女孩却嘲笑她：“肚子都大成这样了，竟然还坐地铁出来赚钱？”，之后金智英“理所当然”的放弃她所有的生活，朋友圈，工作，以及自己的梦想，一门心思照顾自己的孩子，每日重复着一样的工作：换尿不湿，做饭，洗衣服，收拾衣服，在别人眼里可能稍微动动手就可以完成的工作占据了她将近10小时的生活，每天也就将孩子送去学校之后有短暂的时间供她休息娱乐，而恰巧就是因为这个短暂的娱乐，在别人眼里就成为了在家享清福，白花男人钱的败家妇女，无处发泄的金智英只好在晚上向丈夫诉苦，而她得到的是“我已经在帮你啦，大家都很累的啦，共同体谅一下啦”。种种在他人看来不起眼的事情越积越多，导致了金智英的产后抑郁症。</p><p>书中令我感触蛮深的是金智英和她的女性组长在职场发生的事情，在她们眼里，自己会因为结婚生孩而耽误公司的正常发展，所以想尽办法加班加点，通过自己微薄的努力弥补因生小孩照顾小孩而缺席工作所带来的不良后果。可实际是，大家并不会因此而同情她们，相反 ，他们早已认为这样的行为是正确的，根本不足以放在口边提起而让他人钦佩。一次次的让步妥协导致了女性在职场上的话语权越来越少，本是自己的权利却不好好珍惜，在利益面前大家都是没有血肉的禽兽罢了，谁会考虑他人的权益呢。在遭遇了厕所偷拍事件后，组长冒着失去工作的风险和老板据理力争，这就像一个信号一样，警醒着正在读书的女性群体，是时候拿起自己的武器捍卫自己的权利了。也就是在去年，我妹在班里受到了同学的欺负，暂且先不谈原因，我妹在这件事的态度和做法上和金智英简直如出一辙，而这变相导致了她被同学欺负的次数越来越多，她的母亲也在劝导她，别理那些欺负她的人就是了，话语间根本看不到反抗的意思。回家的那天晚上，我给我妹说，只要你有理，拉着欺负你的同学直接找老师，把事情说清楚，不用害怕什么，你哥在你后面帮你，一定要硬起来！无论是在生活还是工作，忍气吞声就意味着他人可以变本加厉的要求你做一些本不属于你的事情。</p><p>再者谈到生儿育女，记得之前看过一个姚晨主演的《找到你》，离婚职场女性因缺乏对孩子的照顾，了解与教育而差点失去孩子的故事。或许父母在照顾孩子方面寻找到平衡是人类社会永恒的话题吧，天平稍微偏向哪一边都不行，而现实是，女性担任了绝大部分在男性看来微不足道的家庭主妇的工作，男主外，女主内的生活模式早已成为社会的常态。我一个现在都没有女朋友的人都先不谈这种模式的好坏了，其实我想说的更多是尊重与理解，站在女性的角度看这个问题，谁能日复一日重复一样枯燥而乏味的工作呢。生儿育女从来都不是一个人的事情，哪怕男性回家后的几句鼓励与安慰，都可以让临近崩溃的女性重燃生命之火。作为男性，我想更多的是在家务方面为女性分担责任，将出席酒局的时间换成拖地打扫换尿布，两个人共同努力才应是这个社会所推崇且鼓励的。</p><p>关于工作，书中也对女性有所限制，其实作为父母可以理解，谁都想着自己的孩子能有一份安稳的工作，哪怕放到当今的中国，仍是绝大部份家庭所选择的道路。记得之前看过一篇文章，美国人选择 CS 专业不仅仅是赚的钱多，更多的是为了后代可以选择自己喜欢的事情，比如画画音乐而不用担心家里的资金问题，当后代的后代逐渐把家里的钱花完的时候，会继续从事 CS 等薪资高的工作，仿佛是一个闭环，几代人奋斗着，几代人享福着。当金智英的姐姐“成功”被母亲劝说，放弃自己热爱且带点空想的梦想而投身教育这个铁饭碗的时候，金智英的母亲难以抑制住心中的悔恨。面对社会的压力，谁是失败的一方，而谁又是成功的一方呢。</p><p>都是苟活在残缺的世界里，拥有着伟大的梦想的一个个羸弱的蝼蚁们。</p><hr><p>书中摘要：</p><p>原来母亲对自己的人生、对自己因为育儿而放弃梦想感到遗憾。一时间，金智英觉得自己宛如一块体积虽小却奇重无比的石头，紧紧地压住母亲的裙角，使她无法继续向前。金智英感到有些自责，母亲似乎察觉到她的难过，默默地用手顺了一下她的头发，将其整齐地塞往耳后。<br>(Kindle Locations 311-314).</p><p>“当然要把那狗娘养的变态手折断啊！<br>(Kindle Location 1001).</p><p>无奈，她自己的日常已处于水深火热当中，每天都战战兢兢，片刻不得松懈，一个不小心就可能掉入万丈深渊，实在无暇再照顾另一个人，也没有多余的心思好好安慰别人。久而久之，就像冰箱上或浴室搁架上堆积已久却从未清理的灰尘一样，两人心中也渐渐充满对彼此的埋怨。<br>(Kindle Locations 1180-1182).</p><p>这个社会看似改变了很多，可是仔细窥探内部细则和约定俗成，便会发现其实还是固守着旧习，所以就结果而论，应该说这个社会根本没有改变。<br>(Kindle Locations 1324-1325).</p><p>“你不是说叫我不要老是只想着失去吗？我现在很可能会因为生了孩子而失去青春、健康、工作，以及同事、朋友等社会人脉，还有我的人生规划、未来梦想等种种，所以才会一直只看见自己失去的东西，但是你呢？你会失去什么？”<br>(Kindle Locations 1367-1369).</p><p>金智英与郑代贤讨论了很多种可能性，他们将生完小孩马上回去上班、请一年的育婴假然后再去上班、永远不回去上班这三种可能写在纸上，并整理出每一种情况诸如谁会是孩子的主要照顾者、需要投入多少费用、分别有哪些优缺点等。要是夫妻都坚持继续工作，那么孩子就只能拜托在釜山的公婆帮忙照顾，或者请一名保姆来家里全天帮忙。然而，拜托公婆照顾孙子还是有难度<br>(Kindle Locations 1431-1435).</p><p>“能不能不要再说‘帮’我了？帮我做家务，帮我带小孩，帮我找工作，这难道不是你的家、你的事、你的孩子吗？再说，要是我去工作，赚来的钱难道都只花在我身上吗？干吗说得好像是发善心帮别人做事一样？”<br>(Kindle Locations 1446-1448).</p><p>但她实在不喜欢听到有人说她伟大或了不起，因为一旦挂上那样的头衔，似乎就会变得连叫苦都不应该。<br>(Kindle Locations 1518-1519).</p><p>其实写这本书的过程中，我对金智英一直充满着不舍和无奈，但我清楚地知道，这就是她的成长背景、她的生活，别无他法，因为我自己亦是如此。我认为，对于凡事总是谨慎做决定、忠于自己的选择、全力以赴的金智英来说，这个社会应该给予她合理的补偿与鼓励，也应该给予她更多机会和选择余地才是。我自己有一个比芝媛大五岁的女儿，她说长大以后想要当航天员或科学家。我希望，我相信，也努力地想办法让女儿的成长背景可以比我过去的成长环境更美好，由衷期盼世上每一个女儿，都可以怀抱更远大、更无限的梦想。<br>(Kindle Locations 1800-1806).</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>1/1/2019 - 12/31/2019</title>
      <link href="/1-1-2019%20-%2012-31-2019.html"/>
      <url>/1-1-2019%20-%2012-31-2019.html</url>
      
        <content type="html"><![CDATA[<p>本来这篇随记是准备12.7号，也就是托福出分的那一天发的，结果之后一直在忙申请，也没有心情继续完成剩下的内容。正好趁着2019最后一天，把随记写完，也算是给自己一个交代了。<a id="more"></a></p><p>2019年12月7号中午，正和朋友在一起吃饭，刷手机的时候想着看看托福出分了没有，突然一个激灵，best score刷新了，个位数从0变成了5，仔仔细细看了各个单项的分数和刷新时间，没错，都是12.1的最高分，105，托福，终于分手了。</p><p>饭后去中介的路上，给我家人，老师，朋友，前女友都发送了我分手的消息，真的，太高兴了。晚上躺在床上一直到了凌晨2点都没有睡去，一部分原因，可能还是担心这一切都是一场梦。那时的我，还会上托福的官网，输入自己的账户密码，再三确认顶上的信息是否正确，成绩有没有错误。还记得我托福首考75分，拿到成绩的那一刻，我真的不知道怎么办。摸爬滚打，在90分段停留了3次，一次次的报考，一次次点开成绩时那急促的心跳声，终于在那一天结束了。还记得今年寒假在学校，和同学在路上聊天抱怨托福精听的痛苦，暑假在图书馆一天花上7个小时背GRE单词，当时我没有想太多，只知道，我的时间真的不多了。在这之前。我有梦见过自己托福分手了，考了109，在梦里直接笑醒了，醒了之后很失落，竟然tm没有真正发生。从2018年7月一直到2019年12月，我和你纠缠太久了，是时候结束这段不了情了，再见，托福。</p><p>很多人说 100分的托福是一把钥匙，可以打开更多的世界，的确，那时的我，已经被门外世界搞得头晕眼花了。100分，意味着我有更大的可能性申请到更好的学校，享受更好的教育资源和更高质量的校友网络。12.1考之前，我的选校更多的是USC之类的不太注重托福成绩而看重GPA的学校，可想而知，留给我的选择并不是很多，很多人，包括老师都告诉我，托福上了100，你的选校就可以大胆些，因为有些学校是存在机筛T100的情况的，GPA稍微有点高的情况却因为托福而不能真正发挥自己的实力，实属有些可惜，但在当时，也就是12.1之前，我真的没有想太多，USC对我来说已经足矣。12.7之后，我大胆的选择了哥大，JHU，CMU，UCSD这样的“名校”，和清北，浙大，上交，复旦的同学一起竞争，虽不知道结果怎么样，但是当我每次查看这些学校的帖子，看上面的人说这类学校的各种好处，我就在想，既然我有能力，有资格申请这些学校，为何不尝试一下，即使失败了，也可以告诉我自己，我最起码尝试过了，不后悔。</p><p>今年我大学就毕业了，填写申请的时候，一条一条输入自己的成绩，每一个花费数十小时的科目在纸上不过是一个不起眼的数字，那一张纸基本总结了我将近4年的大学生活。看到拿到90+的科目不自觉的会骄傲一下，那些70+的科目也会抱怨一下自己当初为什么不再努力一下，但不管怎么样，过去了就过去了，所有的成就，努力，都在我提交申请的那一刻截止了，1月1号是INI@CMU的申请截止时间，因为推荐信的原因我最终放弃了这个项目，敲定了11所学校的11个项目: 西北大学，东北大学，纽约大学，哥伦比亚大学，伊利诺伊香槟分校，卡内基梅隆大学，南加州大学，加州大学圣地亚哥分校，加州大学欧文分校，约翰霍普金斯大学，杜克大学。除了CMU是SE方向外，其余的都是纯CS方向。终于还是和大伙一起，挤上了CS的独木桥。</p><p>也就是在今年，我接触到了Telegram，QuantumultX和Surge，Telegram让我接触到了很多很多的大佬，QuantumultX和Surge让我接触到了JS，也就有了现在80个star的项目，2篇介绍性质的博客。总感觉有了需求，通过向别人请教知识，自己动手学习，写代码，最终完成后别人一句句的“谢谢你呀”“说谢谢的应该是我，是你帮助了那么多”才是让我真正快乐的事情。我很享受这样的过程，也很乐意帮助别人解决问题，谢谢大家的鼓励与帮助，是你们让我更加珍惜生活中一点一滴的美好。</p><p>今年跨年去摩尔曼斯克看极光的计划泡汤了，取而代之的是到上海找同学玩，看开心麻花话剧，之后回北京听音乐会，去孔庙、卧佛(offer)寺求得好的录取结果，最后回到郑州跨年+写总结博客。再过几天，我就要去新加坡做毕设了，方向是分布式计算的，其实我内心有一个想法，就是想仔细去钻研，搞懂一个方向，大家以后作为软件工程师在岗位上不过是任人摆布的棋子，换做是其他人，一样可以胜任，我能做到，就是多会一点东西，像分布式计算这个东西在很多方面都有应用，或许正是我对这个方向稍有研究，就是以后面试工作中战胜别人的筹码。</p><p>当拿到offer之后，真正的竞争就开始了，刷题找实习找工作取代了申请，成为了下一阶段最重要的目标。前路不可能风平浪静了，2020年，一波人结束申请，一波人着手申请，一波人辞去工作，一波人拿到大厂offer，一波人考上研究生，一波人默默准备二战，变化太多也太快了，我还是希望我自己，能多看几本书，闲下心能写写信，画几张画，当然还要刷题。我出国前的checklist只完成了 换一个电脑 。还有很多很多事情等着我去努力，去实践，去完成，2020，大家一起加油，1月4，5号最后一次托福的朋友们也要加油，我们美国见！</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>微博超话自动签到脚本</title>
      <link href="/%E5%BE%AE%E5%8D%9A%E8%B6%85%E8%AF%9D%E8%87%AA%E5%8A%A8%E7%AD%BE%E5%88%B0%E8%84%9A%E6%9C%AC.html"/>
      <url>/%E5%BE%AE%E5%8D%9A%E8%B6%85%E8%AF%9D%E8%87%AA%E5%8A%A8%E7%AD%BE%E5%88%B0%E8%84%9A%E6%9C%AC.html</url>
      
        <content type="html"><![CDATA[<h1 id="脚本介绍"><a href="#脚本介绍" class="headerlink" title="脚本介绍"></a>脚本介绍</h1><p>最后一次考托之前，群里一位小伙伴说想搞一个微博超话的签到脚本，当时准备考试加上不知道怎么处理 Cookie，这个脚本一直处于停滞的状态，前几天 QuantumultX 更新了定时脚本以及持久化存储的 API，<a id="more"></a> <a href="https://t.me/nubida" target="_blank" rel="noopener">野比大佬</a>完成了<a href="https://t.me/NobyDa/116" target="_blank" rel="noopener">京东签到</a>的脚本，于是我在此基础上修改了部分的代码，完成了微博超话签到的脚本。该签到脚本总体来说是两个脚本联动的作用，一个脚本捕捉http请求中的 Cookie，也就是微博超话签到的 Cookie，并用持久化存储的 API 进行保存，再利用另外一个定时脚本读取对应的 Cookie，利用get方法对指定的签到url进行操作，最终实现了超话的签到。在前期的测试阶段，我以为不同的超话对应了不同的请求，所以对应的cookie也就不一样了，在后来的测试阶段发现，这些超话可以共用一个cookie，所以代码逻辑也就没有之前那么复杂了。</p><p>这个脚本的完成，要感谢 <a href="https://t.me/asukanana" target="_blank" rel="noopener">nana asuka</a> , <a href="https://t.me/pxd0207" target="_blank" rel="noopener">Just wanna be with you</a>, <a href="https://t.me/nubida" target="_blank" rel="noopener">野比</a> , <a href="https://t.me/iNotification" target="_blank" rel="noopener">Info</a>,  <a href="https://t.me/wangfei021325" target="_blank" rel="noopener">灰灰</a>的帮助，如果大家觉得这个项目对你有帮助，不妨 <strong>Star一下我的 <a href="https://github.com/NavePnow/Profiles" target="_blank" rel="noopener">Repo</a></strong>(最近在申请美国的研究生，有些学校还是挺看重这个的) 谢谢大家了。</p><h1 id="Check-in-for-Surge"><a href="#Check-in-for-Surge" class="headerlink" title="Check in for Surge"></a>Check in for Surge</h1><center><img src="https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_1202.JPG" height="60%" width="60%"></center><ul><li><p><strong>配置获取cookie脚本</strong><br>  将 <a href="https://raw.githubusercontent.com/NavePnow/Profiles/master/Scripts/weibo/get_cookie_surge.js" target="_blank" rel="noopener">get_cookie_surge.js</a> 保存在 Surge/Scripts 下面，在配置文件中添加如下代码</p><pre><code>[Script]http-request https:\/\/weibo\.com\/p\/aj\/general\/button\?ajwvr=6&amp;api=http:\/\/i\.huati\.weibo\.com\/aj\/super\/checkin max-size=0,script-path=get_cookie_surge.js[MITM]hostname = weibo.com</code></pre><p>  或者直接利用云端 js</p><pre><code>[Script]http-request https:\/\/weibo\.com\/p\/aj\/general\/button\?ajwvr=6&amp;api=http:\/\/i\.huati\.weibo\.com\/aj\/super\/checkin max-size=0,script-path=https://raw.githubusercontent.com/NavePnow/Profiles/master/Scripts/weibo/get_cookie_surge.js[MITM]hostname = weibo.com</code></pre></li><li><p><strong>获取超话id</strong></p><ol><li><p>同样在配置文件中加上如下代码 (其作用是强制手机浏览器访问电脑端超话页面)</p><pre><code>[Header Rewrite]^https?://weibo\.com/p/[0-9] header-replace User-Agent &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.2 Safari/605.1.15&quot;</code></pre></li><li><p>打开微博应用，在我的-&gt;超话社区中选择需要操作的社区，点击右上角的三个点，复制对应的链接</p></li><li><p>将复制的链接粘贴到浏览器中打开，例如 <a href="https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038" target="_blank" rel="noopener">https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038</a>,  <code>1008080c5fb650788fe5c7577f0b6ec4a34038</code> 就是我们需要的超话id</p><ul><li>如果页面还是移动端排版，请检查 <code>Rewrite</code> 是否生效，</li><li>如果没有显示签到按钮，请点击 <code>发帖按钮</code> 进行微博账号的登录</li></ul></li></ol></li><li><p><strong>获取 Cookie</strong><br>  打开超话网页，例如 <a href="https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038" target="_blank" rel="noopener">https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038</a>，点击 <code>签到/已签到</code> 按钮，Surge 会弹出通知，提示获取 Cookie 成功。<strong>(多超话签到不需要获取多个Cookie，只需要记住每个超话的id即可)</strong></p><center><img src="https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_1203.jpg" height="40%" width="40%"></center></li><li><p><strong>配置签到脚本</strong></p><ol><li><p>将 <a href="https://raw.githubusercontent.com/NavePnow/Profiles/master/Scripts/weibo/checkin_surge.js" target="_blank" rel="noopener">checkin_surge.js</a> 保存在 Surge/Scripts 下面，打开脚本，修改部分内容</p><pre><code>const accounts = [    [&quot;title&quot;, &quot;id&quot;]]</code></pre><p>超话信息的填写要严谨按照代码示例的格式填写，内容顺序依次为 <strong>超话名称、超话id</strong>，2个内容用双引号””括起来，且不需要urlencode，直接原文显示，注意不同超话间用逗号隔开。<br>示例:</p><pre><code>const accounts = [    [&quot;IU&quot;, &quot;100808d4151ccebfbae55e8f7c0f68f6d18e4d&quot;],    [&quot;SWITCH&quot;, &quot;1008084239f063a3d4fb9d38a0182be6e39e76&quot;],    [&quot;林允儿&quot;, &quot;1008080c5fb650788fe5c7577f0b6ec4a34038&quot;],    [&quot;泰妍&quot;, &quot;100808377e60b6bf5ffc9cdc603cc93b75c663&quot;],    [&quot;Apple&quot;, &quot;1008089f6290f4436e5a2351f12e03b6433c3c&quot;]]</code></pre></li><li><p>进入 配置文件 的文本编辑模式，在配置文件中添加如下代码</p><pre><code>[Script]cron &quot;00 12 * * *&quot; script-path=checkin_surge.js</code></pre><p>以上实例为 每天中午12:00 运行存放于 本地的 checkin_surge.js 脚本，自定义触发时间配置使用的是 crontab 样式，api可参考 <a href="https://community.nssurge.com/d/33-scripting" target="_blank" rel="noopener">Scripting</a> 的介绍</p></li></ol></li></ul><h1 id="Check-in-for-QuantumultX"><a href="#Check-in-for-QuantumultX" class="headerlink" title="Check in for QuantumultX"></a>Check in for QuantumultX</h1><center><img src="https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_1195.JPG" height="60%" width="60%"></center><ul><li><p><strong>配置获取cookie脚本</strong><br>  将 <a href="https://raw.githubusercontent.com/NavePnow/Profiles/master/Scripts/weibo/get_cookie_qx.js" target="_blank" rel="noopener">get_cookie_qx.js</a>保存在 QuantumultX/Scripts 下面，在配置文件中添加如下代码</p><pre><code>[rewrite_local]https:\/\/weibo\.com\/p\/aj\/general\/button\?ajwvr=6&amp;api=http:\/\/i\.huati\.weibo\.com\/aj\/super\/checkin url script-request-header get_cookie_qx.js[mitm]hostname = weibo.com</code></pre></li><li><p><strong>获取超话id</strong></p><ol><li><p>同样在配置文件中加上如下代码 (其作用是强制手机浏览器访问电脑端超话页面)</p><pre><code>[rewrite_local]^https?://weibo\.com/p/[0-9] url request-header (\r\n)User-Agent:.+(\r\n) request-header $1User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.2 Safari/605.1.15</code></pre></li><li><p>打开微博应用，在我的-&gt;超话社区中选择需要操作的社区，点击右上角的三个点，复制对应的链接</p></li><li><p>将复制的链接粘贴到浏览器中打开，例如 <a href="https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038" target="_blank" rel="noopener">https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038</a>,  <code>1008080c5fb650788fe5c7577f0b6ec4a34038</code> 就是我们需要的超话id</p><ul><li>如果页面还是移动端排版，请检查 <code>Rewrite</code> 是否生效，</li><li>如果没有显示签到按钮，请点击 <code>发帖按钮</code> 进行微博账号的登录</li></ul></li></ol></li><li><p><strong>获取 Cookie</strong><br>  打开超话网页，例如 <a href="https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038" target="_blank" rel="noopener">https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038</a>，点击 <code>签到/已签到</code> 按钮，QuantumultX 会弹出通知，提示获取 Cookie 成功。<strong>(多超话签到不需要获取多个Cookie，只需要记住每个超话的id即可)</strong></p><center><img src="https://raw.githubusercontent.com/NavePnow/blog_photo/master/IMG_1197.PNG" height="40%" width="40%"></center></li><li><p><strong>配置签到脚本</strong></p><ol><li><p>将 <a href="https://raw.githubusercontent.com/NavePnow/Profiles/master/Scripts/weibo/checkin_qx.js" target="_blank" rel="noopener">checkin_qx.js</a> 保存在 QuantumultX/Scripts 下面，打开脚本，修改部分内容</p><pre><code>var accounts = [    [&quot;title&quot;, &quot;id&quot;]]</code></pre><p>超话信息的填写要严谨按照代码示例的格式填写，内容顺序依次为 <strong>超话名称、超话id</strong>，2个内容用双引号””括起来，且不需要urlencode，直接原文显示，注意不同超话间用逗号隔开。<br>示例:</p><p> var accounts = [</p><pre><code>[&quot;IU&quot;, &quot;100808d4151ccebfbae55e8f7c0f68f6d18e4d&quot;],[&quot;SWITCH&quot;, &quot;1008084239f063a3d4fb9d38a0182be6e39e76&quot;],[&quot;林允儿&quot;, &quot;1008080c5fb650788fe5c7577f0b6ec4a34038&quot;],[&quot;泰妍&quot;, &quot;100808377e60b6bf5ffc9cdc603cc93b75c663&quot;],[&quot;Apple&quot;, &quot;1008089f6290f4436e5a2351f12e03b6433c3c&quot;]</code></pre><p> ]</p></li><li><p>进入 配置文件 的文本编辑模式，在配置文件中添加如下代码</p><pre><code>[task_local]00 12 * * * checkin_qx.js</code></pre><p>以上实例为 每天中午12:00 运行存放于 本地的 checkin_qx.js 脚本，自定义触发时间配置使用的是 crontab 样式，api可参考 <a href="https://community.nssurge.com/d/33-scripting" target="_blank" rel="noopener">Scripting</a> 的介绍</p></li></ol></li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>由于 Cookie 时效性问题，不能保证每次签到都成功，如果提示签到失败，请重新获取 Cookie，获取方法: 打开任意一个超话链接，例如 <a href="https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038" target="_blank" rel="noopener">https://weibo.com/p/1008080c5fb650788fe5c7577f0b6ec4a34038</a>, 点击 <code>签到/已签到</code> 按钮，脚本提示写入 Cookie 成功。</p><ul><li><p><strong>反馈</strong></p><p>  💡 如果大家运行不了脚本或者运行出错，<a href="https://t.me/Leped_Bot" target="_blank" rel="noopener">反馈</a>的时候一定要带上报错的截图，有能力的同学在代码里面添加<code>console.log()</code>，并附上 Surge/QuantumultX log的对应截图，感谢大家。</p></li></ul><h1 id="脚本下载"><a href="#脚本下载" class="headerlink" title="脚本下载"></a>脚本下载</h1><p>👉 <a href="https://github.com/NavePnow/Profiles/tree/master/Scripts/weibo" target="_blank" rel="noopener">Check in</a> </p><h1 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h1><p>Telegram: <a href="https://t.me/Leped_Bot" target="_blank" rel="noopener">Leped_Bot</a></p><p>GitHub: <a href="https://github.com/NavePnow" target="_blank" rel="noopener">NavePnow</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式计算学习笔记(三) Ray —API &amp; Actors</title>
      <link href="/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%89-Ray%20%E2%80%94API%20&amp;%20Actors.html"/>
      <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%89-Ray%20%E2%80%94API%20&amp;%20Actors.html</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本篇博客主要介绍 Ray API 简单的使用（基于actor和worker），以及运行一个简单的利用 Ray 进行修改的传统神经网络模型(MNIST)</p><a id="more"></a><p>Actor: 有状态的 worker，当实例化一个新actor时，将创建一个新worker，并将acto的方法调度到该特定worker上，并且可以访问该worker并更改其状态。</p><p>CSDN: <a href="https://blog.csdn.net/weixin_43255962/article/details/88850456" target="_blank" rel="noopener">Ray入门指南（3）—-Ray API</a></p><p>可以简单的理解为，在函数上加入 <code>@ray.remote</code>之后，这个函数就是 <code>worker</code>，在类上加入<code>@ray.remote</code>之后，这个类就是actor(有状态的workers)</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> os</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> ray</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> tensorflow.compat.v1 <span class="hljs-keyword">as</span> tf</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">tf.disable_v2_behavior()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">ray.init(num_gpus=<span class="hljs-number">8</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># consruct neural network</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">construct_network</span><span class="hljs-params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># [None, 784]: data structure. total number of attribute is 28*28=784 with uncertain row number (batch size, can be of any size.)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    x = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">784</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># total number of attribute is 10 (0-9) with uncertain row number</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    y_ = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">10</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    W = tf.Variable(tf.zeros([<span class="hljs-number">784</span>, <span class="hljs-number">10</span>]))  <span class="hljs-comment"># Weights</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    b = tf.Variable(tf.zeros([<span class="hljs-number">10</span>]))  <span class="hljs-comment"># biase</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    y = tf.nn.softmax(tf.matmul(x, W) + b) <span class="hljs-comment"># y = wx + b</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># y_: real，y: prediction</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ *</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">                                                  tf.log(y), reduction_indices=[<span class="hljs-number">1</span>]))  <span class="hljs-comment"># loss function</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># Use gradientdescentoptimizer to min the loss function</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">    train_step = tf.train.GradientDescentOptimizer(<span class="hljs-number">0.5</span>).minimize(cross_entropy)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># 1:search by row. tf.equal: 对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，反正返回False</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">    correct_prediction = tf.equal(tf.argmax(y, <span class="hljs-number">1</span>), tf.argmax(y_, <span class="hljs-number">1</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) <span class="hljs-comment"># tf.cast： convert correct_prediction to float32</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> x, y_, train_step, accuracy</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># define actor for structure</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote(num_gpus=1)  # actor gpu数量为1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NeuralNetOnGPU</span><span class="hljs-params">(object)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, mnist_data)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line">        self.mnist = mnist_data</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-comment"># Set an environment variable to tell TensorFlow which GPUs to use. Note</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-comment"># that this must be done before the call to tf.Session.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line">        os.environ[<span class="hljs-string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="hljs-string">","</span>.join(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line">            [str(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> ray.get_gpu_ids()])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">with</span> tf.Graph().as_default():</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">"/gpu:0"</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line">                self.x, self.y_, self.train_step, self.accuracy = construct_network()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># Allow this to run on CPUs if there aren't any GPUs.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">                config = tf.ConfigProto(allow_soft_placement=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment">#### normal network</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># init = tf.initialize_all_variables()</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># sess = tf.Session()</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># sess.run(init)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment">####</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">50</span></pre></td><td class="code"><pre><span class="line">                self.sess = tf.Session(config=config)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">51</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-comment"># Initialize the network.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">52</span></pre></td><td class="code"><pre><span class="line">                init = tf.global_variables_initializer()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">53</span></pre></td><td class="code"><pre><span class="line">                self.sess.run(init)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">54</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">55</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(self, num_steps)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">56</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_steps):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">57</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-comment"># load dataset by batch</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">58</span></pre></td><td class="code"><pre><span class="line">            batch_xs, batch_ys = self.mnist.train.next_batch(<span class="hljs-number">100</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">59</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-comment"># train</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">60</span></pre></td><td class="code"><pre><span class="line">            self.sess.run(self.train_step, feed_dict=&#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">61</span></pre></td><td class="code"><pre><span class="line">                          self.x: batch_xs, self.y_: batch_ys&#125;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">62</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-keyword">if</span> (i% <span class="hljs-number">50</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">63</span></pre></td><td class="code"><pre><span class="line">                print(self.get_accuracy())</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">64</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_accuracy</span><span class="hljs-params">(self)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">65</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span> self.sess.run(self.accuracy, feed_dict=&#123;self.x: self.mnist.test.images,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">66</span></pre></td><td class="code"><pre><span class="line">                                                       self.y_: self.mnist.test.labels&#125;)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">67</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">68</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">69</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># load MNIST dataset，并告诉Ray如何序列化定制类。</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">70</span></pre></td><td class="code"><pre><span class="line">mnist = input_data.read_data_sets(<span class="hljs-string">"MNIST_data"</span>, one_hot=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">71</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">72</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Create the actor. 实例化actor并运行构造函数</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">73</span></pre></td><td class="code"><pre><span class="line">nn = NeuralNetOnGPU.remote(mnist)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">74</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">75</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Run a few steps of training and print the accuracy.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">76</span></pre></td><td class="code"><pre><span class="line">nn.train.remote(<span class="hljs-number">200</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">77</span></pre></td><td class="code"><pre><span class="line">accuracy = ray.get(nn.get_accuracy.remote()) <span class="hljs-comment"># ray.get 从对象ID中进行数据的读取（python对象）</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">78</span></pre></td><td class="code"><pre><span class="line">print(<span class="hljs-string">"Accuracy is &#123;&#125;."</span>.format(accuracy))</span></pre></td></tr></table></figure><p>相较于传统的神经网络结构，通过使用 Ray 进行了网络的封装，利用 Api 的形式进行网络调用，<code>construt_network()</code> 函数中定义了输入变量，权重，偏执，通过 softmax 隐藏层输出结果，同时利用交叉熵定义了损失函数，最终函数返回 输入，预测的结果，训练步数以及准确率。</p><p>在定义 Ray actor（类）中，进行了网络结构的初始化，训练的工作。这些函数的实现和没有使用 Ray 没有太大的差别，可以理解为进行了更为高级的封装便于 Ray 分布式框架的实现</p><p>Output:</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9017</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.907</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9047</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9047</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9025</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">Accuracy is 0.9049000144004822.</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9026</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9059</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9088</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9067</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">(pid&#x3D;20686) 0.9049</span></pre></td></tr></table></figure><p>在训练过程中，每50步进行结果的输出，其结果输出到终端，有图中可以得知，由于多进程工作，而只有一个位置进行结果的输出，难免会有优先抢断的问题，所以本应是最后输出的 Accuracy 放在了较为靠前的位置。</p><p>Q&amp;A: </p><ol><li><p>python 中 <code>__init__(self)</code> 以及类的使用<br> <code>_init_(self)</code> 可以理解为JAVA的构造函数<br> 实例化类的时候会最先调用构造函数  </p></li><li><p>python class中不同函数的调用以及self的使用</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyClass</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">pass</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func1</span><span class="hljs-params">(self)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># do something</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    print(<span class="hljs-string">'a'</span>)   <span class="hljs-comment">#for example      </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    self.common_func()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func2</span><span class="hljs-params">(self)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># do something</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    self.common_func() <span class="hljs-comment"># self表示类的实例</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">     </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">common_func</span><span class="hljs-params">(self)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">pass</span></span></pre></td></tr></table></figure></li><li><p>Tensorflow 的基本定义以及使用<br> <code>input-&gt; hidden layer -&gt; output layer -&gt; 梯度下降进行参数的训练</code><br> 用优化器 (optimizer) 减小误差<br> <code>sess.run(Weights)</code>: sess类似于指针，用sess.run 指向网络结构中的 Weights，进行输出<br> <code>placeholder</code>: 在session run的时候再进行数据的传入，可以理解为占一个位置<br> 只要是通过 <code>placeholder</code> 进行运算的东西，在sess.run里面都需要进行定义相关运算的参数</p> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">feed_dict&#x3D;&#123;xs:x_data, ys:y_data&#125;</span></pre></td></tr></table></figure><p> <code>cross_entropy</code>: 交叉熵，用于目标与预测值之间的差距</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Distributed System </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分布式计算学习笔记(二) Ray —远程对象与远程函数</title>
      <link href="/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C-Ray%20%E2%80%94%E8%BF%9C%E7%A8%8B%E5%AF%B9%E8%B1%A1%E4%B8%8E%E8%BF%9C%E7%A8%8B%E5%87%BD%E6%95%B0.html"/>
      <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C-Ray%20%E2%80%94%E8%BF%9C%E7%A8%8B%E5%AF%B9%E8%B1%A1%E4%B8%8E%E8%BF%9C%E7%A8%8B%E5%87%BD%E6%95%B0.html</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本篇博客主要介绍 Ray 远程对象，远程函数以及 Ray 进程之间并行的实现。</p><a id="more"></a><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>下学期去新加坡做毕设，老师给我订的主题是关于Ray-分布式执行框架的内容，其实就是想让我在这个框架中做一些应用，也可以说是大众化？前几天和HUST的挂名老师聊了聊，她也没有听说过这个框架，在网上搜了一下，说让我尝试一下在这个分布式执行框架中实现一个聚类算法，关键词有 Ray Tensor Clustering, 说实话，不懂，真的，看一个名次就会蹦出5个之前没见过的，多个名字叠加直接把我搞懵逼了。所以这个系列也算是我的学习笔记吧。</p><h2 id="Ray-概述"><a href="#Ray-概述" class="headerlink" title="Ray 概述"></a>Ray 概述</h2><p>Ray是UC Berkeley RISELab新推出的高性能分布式执行框架，它使用了和传统分布式计算系统不一样的架构和对分布式计算的抽象方式，具有比Spark更优异的计算性能。</p><ul><li>优点:<ul><li>海量任务调度能力。</li><li>毫秒级别的延迟。</li><li>异构任务的支持。</li><li>任务拓扑图动态修改的能力。</li></ul></li><li>缺点：<ul><li>API层以上的部分还比较薄弱，Core模块核心逻辑估需要时间打磨。</li><li>国内目前除了蚂蚁金服和RISELab有针对性的合作以外，关注程度还很低，没有实际的应用实例看到，整体来说还处于比较早期的框架构建阶段。</li></ul></li><li>用途：<br>  增强学习<ul><li>分类</li><li>聚类</li><li>图像识别</li><li>推荐系统</li><li>文本翻译</li><li>Application: deep reinforcement learning using RLlib, scalable hyperparameter search using Ray Tune, automatic program synthesis using AutoPandas, etc. (advanced library from tutorial)</li></ul></li></ul><h2 id="ray分布式框架的介绍"><a href="#ray分布式框架的介绍" class="headerlink" title="ray分布式框架的介绍"></a>ray分布式框架的介绍</h2><h3 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h3><p><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-str1.png" alt="structure"><br>由图可知，Ray的结构基本符合 <code>master-workers</code> 的工作方式，其中每一个 <code>slave</code> 可以创建多个 <code>workers</code> 并行工作，并且在同一个节点中，<code>workers</code> 有可以共享的内存空间。<br>在终端中运行 <code>ray.init(include_webui=True)</code>之后，会在本地创建 Ray集群环境，打开可视化界面如下。<br><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-str2.png" alt="dashboard"><br>由图可知，本地共创建了1个节点，该节点共有16个 <code>workers</code> 进行工作</p><h3 id="远程对象-不可变"><a href="#远程对象-不可变" class="headerlink" title="远程对象 - 不可变"></a>远程对象 - 不可变</h3><p>远程对象存储在对象存储总，并利用唯一的对象ID进行引用。<br>ray.put() 和 ray.get() : 用过 python 对象和对象ID的转换<br><code>x_id=ray.put(x)</code>：x为 python 对象，其函数返回值为该对象的对象ID ，数据结构为对象id的列表<br><code>x=ray.get(x_id)</code>：x_id_为 对象ID，其函数返回值为该对象ID所对应的python对象 </p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">result_ids = [ray.put(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">result_ids[<span class="hljs-number">0</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">ray.get(result_ids[<span class="hljs-number">0</span>]) <span class="hljs-comment"># 0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">ray.get(result_ids)  <span class="hljs-comment"># [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span></span></pre></td></tr></table></figure><h3 id="远程函数"><a href="#远程函数" class="headerlink" title="远程函数"></a>远程函数</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Normal function</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">add1</span><span class="hljs-params">(a, b)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">return</span> a + b</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># @: Decorator</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">add2</span><span class="hljs-params">(a, b)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">return</span> a + b</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">x_id = add2.remote(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">ray.get(x_id)  <span class="hljs-comment"># 3</span></span></pre></td></tr></table></figure><p>第二个函数（远程函数）中，在调用之后会立即创建一个任务并分配给某一节点上的worker进行异步处理（由系统统一调度）。远程函数的输入参数可以通过值或者对象ID传入，函数返回结果为运算结果的唯一对象 ID。在实际情况汇总，一个远程函数可以返回多个对象ID。简单的异步执行的例子：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> time</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f1</span><span class="hljs-params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    time.sleep(<span class="hljs-number">1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f2</span><span class="hljs-params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    time.sleep(<span class="hljs-number">1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 这个操作需要10秒.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">[f1() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 下面的操作只需要一秒钟(假设系统至少有10个cpu核心)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 在Google Colab中由于服务器的CPU支持超线程技术，下面的操作只使用了5s（单核CPU）</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">ray.get([f2.remote() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>)])</span></pre></td></tr></table></figure><p>远程函数输入与返回的例子：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">add2.remote(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">add2.remote(<span class="hljs-number">1</span>, ray.put(<span class="hljs-number">2</span>)) <span class="hljs-comment"># 系统将从对象存储中检索相应的对象</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">add2.remote(ray.put(<span class="hljs-number">1</span>), ray.put(<span class="hljs-number">2</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote(num_return_vals=3)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">return_multiple</span><span class="hljs-params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">a_id, b_id, c_id = return_multiple.remote()</span></pre></td></tr></table></figure><p>任务间的依赖关系：</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_data</span><span class="hljs-params">()</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> np.random.normal(size=<span class="hljs-number">1000</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">aggregate_data</span><span class="hljs-params">(x, y)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> x + y</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 生成一些随机数据。这将启动100个任务，这些任务将在多个节点上并行执行，</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 结果数据将分布在集群的各个节点中（此处假设是在使用ray的分布式集群上使用的）。</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 如果是在一台多核电脑上运行，则会根据核心数进行确定并行的数量。</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 此时date的ID内存中有100*1000个数据</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># data 是100个对象ID的list，每一个对象ID所对应的python对象中共有1000个数据</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">data = [generate_data.remote() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>)]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">print(len(ray.get(data))) <span class="hljs-comment"># 100</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># 执行树缩减，在累积相加过程中，取出两个对象ID所对应的python数据，想对应的数据进行相加，直到只剩下一个数据对象</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">while</span> len(data) &gt; <span class="hljs-number">1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">    data.append(aggregate_data.remote(data.pop(<span class="hljs-number">0</span>), data.pop(<span class="hljs-number">0</span>)))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">#获取结果 1000个数据</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">ray.get(data) <span class="hljs-comment"># 1</span></span></pre></td></tr></table></figure><h3 id="使用-ray-wait-加快进程间的资源等待问题"><a href="#使用-ray-wait-加快进程间的资源等待问题" class="headerlink" title="使用 ray.wait() 加快进程间的资源等待问题"></a><strong>使用 ray.wait() 加快进程间的资源等待问题</strong></h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> time </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> ray </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">ray.init(num_cpus = <span class="hljs-number">4</span>) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span><span class="hljs-params">(x)</span>:</span> </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    time.sleep(random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> x </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_results</span><span class="hljs-params">(results)</span>:</span> </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    sum = <span class="hljs-number">0</span> </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> results: </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">        time.sleep(<span class="hljs-number">1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">        sum += x </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> sum </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">start = time.time() </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">data_list = ray.get([do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">4</span>)]) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">sum = process_results(data_list) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">print(<span class="hljs-string">"duration ="</span>, time.time() - start, <span class="hljs-string">"\nresult = "</span>, sum)</span></pre></td></tr></table></figure><p><code>data_list</code> 调用了4个远程函数进行执行，每个函数之间并行执行，最长时间为4s，之后再统一进行 sum 工作，所以时间等于 <code>4s + time(sum)</code></p><p>为节省时间，利用 <code>ray.wait()</code> 函数进行处理，因为远程函数在调用的时候，会直接返回处理数据所对应的数据ID，即使该ID所对应的数据对象还没有返回，利用这个特性，加上 <code>ray.wait()</code> , 可以完成效率上的巨大提升。</p><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> time </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> random </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> ray </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">ray.init(num_cpus = <span class="hljs-number">4</span>) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-meta">@ray.remote </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">do_some_work</span><span class="hljs-params">(x)</span>:</span> </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    time.sleep(random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> x </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_incremental</span><span class="hljs-params">(sum, result)</span>:</span> </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    time.sleep(<span class="hljs-number">1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> sum + result </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">start = time.time() </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">result_ids = [do_some_work.remote(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">4</span>)] </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">sum = <span class="hljs-number">0</span> </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">while</span> len(result_ids): </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    done_id, result_ids = ray.wait(result_ids) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">    sum = process_incremental(sum, ray.get(done_id[<span class="hljs-number">0</span>])) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">print(<span class="hljs-string">"duration ="</span>, time.time() - start, <span class="hljs-string">"\nresult = "</span>, sum)</span></pre></td></tr></table></figure><p>在循环中，<code>ray.wait()</code> 返回了计算完成的id和还没有完成的id，将完成的id进行函数的计算工作，没有完成的作为循环判断条件继续进行处理，直至所有的任务都已完成。</p><p><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/ray-wait.png" alt="ray.wait()"><br><strong>问题：</strong> 为什么每个都是 <code>done_id[0]</code> ，难道 <code>result_ids</code> 可以完成对 <code>done_id</code> 的某种判断还是像队列一样每次扔掉一个。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://blog.csdn.net/lzc4869/article/details/94663616" target="_blank" rel="noopener">https://blog.csdn.net/lzc4869/article/details/94663616</a></li><li><a href="https://blog.csdn.net/weixin_43255962/article/details/88689665" target="_blank" rel="noopener">https://blog.csdn.net/weixin_43255962/article/details/88689665</a></li><li><a href="http://www.oreilly.com.cn/ideas/?p=2156" target="_blank" rel="noopener">http://www.oreilly.com.cn/ideas/?p=2156</a></li><li><a href="https://www.cnblogs.com/fanzhidongyzby/p/7901139.html" target="_blank" rel="noopener">https://www.cnblogs.com/fanzhidongyzby/p/7901139.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Distributed System </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分布式计算学习笔记(一) 从分布式系统到分布式计算</title>
      <link href="/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80-%E4%BB%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%88%B0%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97.html"/>
      <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80-%E4%BB%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%88%B0%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97.html</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本篇博客主要介绍在学习分布式系统中遇到的一些不懂的专业术语</p><a id="more"></a><h2 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h2><ul><li>Atomicity（原子性）：一個事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。</li><li>Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。</li><li>Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</li><li>Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。<h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2></li><li>Consistency 中文叫做”一致性”。意思是，写操作之后的读操作，必须返回该值。</li><li>Availability 中文叫做”可用性”，意思是只要收到用户的请求，服务器就必须给出回应。</li><li>Partition tolerance，中文叫做”分区容错”, 区间通信可能失败，服务器之间通信失败<h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2>有点 SDN 的感觉，作为南北向的数据接口，连接用户和后端服务器，用户请求首先到达负载均衡器，由负载均衡器分配可用资源（服务器），通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容（通过冗余提高可靠性），以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。<h2 id="协调中心"><a href="#协调中心" class="headerlink" title="协调中心"></a>协调中心</h2>一个用户请求包含多个服务，每个服务又包含多个节点，不同服务之间的转接需要节点间协同配合，提供服务的节点向一个协调中心注册自己的地址，使用服务的节点去协调中心拉取地址，不同节点通过协调中心完成服务的交接。<h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2>Remote Produce Call, 用于服务内不同节点间的远程通信和相互调用<h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h2>分布式系统是一组电子计算机（computer），通过计算机网络相互链接与通信后形成的系统。把需要进行大量计算的工程数据分区成小块，由多台计算机分别计算，在上传运算结果后，将结果统一合并得出数据结论的科学。分布式系统由分布式计算和分布式存储组成，受限于 CAP 特性。<h2 id="分布式计算"><a href="#分布式计算" class="headerlink" title="分布式计算"></a>分布式计算</h2>核心问题： 如何将任务进行分解，如何整合，也就是先Map后Reduce，参考中间件课上所学习的 Word-Count 过程。</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://zhuanlan.zhihu.com/p/32841479" target="_blank" rel="noopener"> https://zhuanlan.zhihu.com/p/32841479</a></li><li><a href="https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1</a></li><li><a href="https://zh.wikipedia.org/wiki/ACID" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/ACID</a></li><li><a href="https://www.ruanyifeng.com/blog/2018/07/cap.html" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2018/07/cap.html</a></li><li><a href="https://blog.csdn.net/trochiluses/article/details/19327639" target="_blank" rel="noopener">https://blog.csdn.net/trochiluses/article/details/19327639</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Distributed System </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hexo主题折腾日记(二) 添加豆瓣和聊天插件</title>
      <link href="/Hexo%E4%B8%BB%E9%A2%98%E6%8A%98%E8%85%BE%E6%97%A5%E8%AE%B0-%E4%BA%8C-%E6%B7%BB%E5%8A%A0%E8%B1%86%E7%93%A3%E5%92%8C%E8%81%8A%E5%A4%A9%E6%8F%92%E4%BB%B6.html"/>
      <url>/Hexo%E4%B8%BB%E9%A2%98%E6%8A%98%E8%85%BE%E6%97%A5%E8%AE%B0-%E4%BA%8C-%E6%B7%BB%E5%8A%A0%E8%B1%86%E7%93%A3%E5%92%8C%E8%81%8A%E5%A4%A9%E6%8F%92%E4%BB%B6.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>今上午翻看别人的博客，看到了Next主题相关优化的帖子，有关于豆瓣主页和博客聊天插件的内容，<a id="more"></a>于是就想在 icarus 主题内也实现这个功能，折腾了一下午，终于搞好了。</p><h2 id="豆瓣主页插件"><a href="#豆瓣主页插件" class="headerlink" title="豆瓣主页插件"></a>豆瓣主页插件</h2><h3 id="实现效果"><a href="#实现效果" class="headerlink" title="实现效果"></a>实现效果</h3><!--more--><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/screenshot 2019-11-17 at 12.18.22.png" height="60%" width="60%"></center><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ol><li>安装模块依赖<br> <code>$ npm install hexo-douban --save</code></li><li>在站点配置文件中添加配置<br> 在 <code>_config.xml</code> 文件中添加 <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">douban:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">  user: mythsman</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">  builtin: false</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">  book:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    title: &#39;This is my book title&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    quote: &#39;This is my book quote&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">  movie:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    title: &#39;This is my movie title&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    quote: &#39;This is my movie quote&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">  game:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    title: &#39;This is my game title&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    quote: &#39;This is my game quote&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">  timeout: 10000</span></pre></td></tr></table></figure></li></ol><p>说明:</p><ul><li>user: 你的豆瓣ID.打开豆瓣，登入账户，然后在右上角点击 “个人主页” ，这时候地址栏的URL大概是这样：”<a href="https://www.douban.com/people/xxxxxx/&quot;" target="_blank" rel="noopener">https://www.douban.com/people/xxxxxx/&quot;</a> ，其中的”xxxxxx”就是你的个人ID了。</li><li>builtin: 是否将生成页面的功能嵌入hexo s和hexo g中，默认是false,另一可选项为true, 如果豆瓣更新频率不高建议选择false，没有必要再每一次部署的时候重新生成豆瓣的页面</li><li>title: 该页面的标题.</li><li>quote: 写在页面开头的一段话,支持html语法.</li><li>timeout: 爬取数据的超时时间，默认是 10000ms ,如果在使用时发现报了超时的错(ETIMEOUT)可以把这个数据设置的大一点。<br>如果只想显示某一个页面(比如movie)，那就把其他的配置项注释掉即可。</li></ul><ol start="3"><li><p>修改/layout/common/article.ejs</p><figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;%- list_categories(post.categories, &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">                    class: 'has-link-grey ',</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">                    show_count: false,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">                    style: 'none',</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">                    separator: '&amp;nbsp;/&amp;nbsp;'</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">                &#125;) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">                &lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">                &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+               &lt;% if (post._content &amp;&amp; word_count(post._content)) &#123; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">                    &lt;% if (!has_config('article.readtime') || get_config('article.readtime') <span class="hljs-comment">=== true) &#123; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">                    &lt;span class="level-item has-text-grey"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">                        &lt;% const words = word_count(post._content); %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">                        &lt;% const time = duration((words / 150.0) * 60, 'seconds') %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">                        &lt;%= `$&#123; time.locale(get_config('language', 'en')).humanize() &#125; $&#123; __('article.read')&#125; ($&#123; __('article.about') &#125; $&#123; words &#125; $&#123; __('article.words') &#125;)` %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">                    &lt;/span&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">                &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+               &lt;% &#125; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">                &lt;% if (!index &amp;&amp; (has_config('plugins.busuanzi') ? get_config('plugins.busuanzi') : false)) &#123; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">                &lt;span class="level-item has-text-grey" id="busuanzi_container_page_pv"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">                    &lt;i class="far fa-eye"&gt;&lt;/i&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">                    &lt;%- _p('plugin.visit', '&lt;span id="busuanzi_value_page_pv"&gt;0&lt;/span&gt;') %&gt;</span></pre></td></tr></table></figure></li><li><p>测试并发布<br><code>hexo douban -bgm &amp;&amp; hexo server</code><br>如果终端没有报错且网页 <code>http://localhost:4000/books</code>, <code>http://localhost:4000/movies</code>, <code>http://localhost:4000/movies</code> 没有问题，就可以直接发布了，这里注意 bgm = books+ games+ movies, 如果前面的配置中只选择了 books，那这里只需要 <code>hexo douban -b</code> 即可，其他同理。</p></li><li><p>主题文件修改<br>在对应主题的 <code>_config.xml</code> 文件 menu 模块添加对应的配置，示例如下。</p> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">menu:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    Home: &#x2F;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    About: &#x2F;about</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    Articles: &#x2F;archives</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    Gallery: &#x2F;gallery</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    Books: &#x2F;books</span></pre></td></tr></table></figure><p>最后测试发布</p></li></ol><h2 id="博客聊天插件"><a href="#博客聊天插件" class="headerlink" title="博客聊天插件"></a>博客聊天插件</h2><h3 id="实现效果-1"><a href="#实现效果-1" class="headerlink" title="实现效果"></a>实现效果</h3><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/screenshot 2019-11-17 at 20.33.21.png" height="40%" width="40%"></center><h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><ol><li>首先需要注册 <a href="https://www.tidio.com/" target="_blank" rel="noopener">Tidio</a> 账号，根据引导填写应用信息。</li><li>在个人主页中选择 <code>Channels -&gt; Live Chat -&gt; Integration</code> ,复制 JS 代码<center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/screenshot 2019-11-17 at 20.37.55.png" height="60%" width="60%"></center></li><li>修改 /layout/layout.ejs, 在文件最后插入对应的代码.<figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">    &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+    &lt;script src="//code.tidio.co/token.js" async&gt;&lt;/script&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">&lt;/body&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">&lt;/html&gt;</span></pre></td></tr></table></figure>其中将<code>token</code>替换成你对应的token即可，接下来可以在 Tidio 控制台的 <code>Channel -&gt; Live chat -&gt; Appearance</code> 中根据提示定制聊天对话框的主题外观和语言包，以适应自己的需求。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hexo主题折腾日记(一) 从cactus到icarus</title>
      <link href="/Hexo%E4%B8%BB%E9%A2%98%E6%8A%98%E8%85%BE%E6%97%A5%E8%AE%B0-%E4%BB%8Ecactus%E5%88%B0icarus.html"/>
      <url>/Hexo%E4%B8%BB%E9%A2%98%E6%8A%98%E8%85%BE%E6%97%A5%E8%AE%B0-%E4%BB%8Ecactus%E5%88%B0icarus.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>从Hexo建站开始，一直是使用的cactus主题，很喜欢那种简约的风格，主页文章预览的都没有的那一种。<a id="more"></a></p><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/IMAGE 2019-11-16 11:11:11.jpg" height="60%" width="60%"></center><p>直到昨天心血来潮想搞一个基于ghost的动态博客，同时爱上了他的默认主题casper，心想这不就是我梦寐已久的主题么，结果搜了很多的资料，发现个人维护的建站工具都是至少1年以上的，有一个基于 python 可以通过ghost部署到github pags上的工具还是基于2.7,我直接裂开，最终直接放弃了这套方案，回过头来想能不能把casper移植到hexo上呢，在github上也搜到了相应的项目，但效果emmm，不是特别能让我满意，贴一张demo供大家参考。</p><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/IMAGE 2019-11-16 11:10:20.jpg" height="60%" width="60%"></center><p>主要还是插件的支持度没有成熟主题的高，然后就又开始google: hexo主题推荐2019类似的关键词，终于发现了这个模版，icarus，没有cactus那么朴素，插件支持度和commit活跃度也比hexo-casper高，所以昨天花了很长很长的时间调整网页布局和文章渲染问题，最终效果我打9分吧，因为还有一点问题没有解决，等写完这个博客我再搞，下面主要把我基于别人修改的模版和自己修改的内容做一下总结，以免以后git pull之后不知道自己做了哪些修改。</p><h1 id="icarus主题之上主要改动"><a href="#icarus主题之上主要改动" class="headerlink" title="icarus主题之上主要改动"></a>icarus主题之上主要改动</h1><ol><li>主页显示两栏widget，文章只显示左边widget</li><li>文章图片居中</li><li>增加profile下面的 bio, 可以放一点自己想说的话</li><li>置顶文章</li><li>文章底部文章详细信息显示以及推荐文章模块配置</li><li>页脚访问人数显示修改</li></ol><h2 id="主页显示两栏widget，文章只显示左边widget"><a href="#主页显示两栏widget，文章只显示左边widget" class="headerlink" title="主页显示两栏widget，文章只显示左边widget"></a>主页显示两栏widget，文章只显示左边widget</h2><p>主要参考 <a href="https://dp2px.com/2019/06/04/icarus-theme/" target="_blank" rel="noopener">水寒blog</a></p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ol><li><p>修改 /includes/helpers/layout.js</p> <figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">hexo.extend.helper.register('column_count', function () &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"> let columns = 1;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+        if (this.page.__post === true || this.page.__page === true) &#123;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+            return 2;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+        &#125;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">const hasColumn = hexo.extend.helper.get('has_column').bind(this);</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">columns += hasColumn('left') ? 1 : 0;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">columns += hasColumn('right') ? 1 : 0;</span></pre></td></tr></table></figure></li><li><p>修改 /layout/common/widget.ejs</p> <figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;%- partial('widget/' + widget.type, &#123; widget, post: page &#125;) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">&lt;% &#125;) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">&lt;% if (position <span class="hljs-comment">=== 'left') &#123; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-deletion">-        &lt;div class="column-right-shadow is-hidden-widescreen &lt;%= sticky_class('right') %&gt;"&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+        &lt;div class="column-right-shadow &lt;%= (page.__page !== true &amp;&amp; page.__post !== true) ? 'is-hidden-widescreen' : '' %&gt; &lt;%= sticky_class('right') %&gt;"&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"> &lt;% get_widgets('right').forEach(widget =&gt; &#123;%&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">     &lt;%- partial('widget/' + widget.type, &#123; widget, post: page &#125;) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"> &lt;% &#125;) %&gt;</span></pre></td></tr></table></figure></li><li><p>修改 /layout/layout.ejs</p> <figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"> &lt;div class="columns"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">         &lt;div class="column &lt;%= main_column_class() %&gt; has-order-2 column-main"&gt;&lt;%- body %&gt;&lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">         &lt;%- partial('common/widget', &#123; position: 'left' &#125;) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+                &lt;% if (page.__page !== true &amp;&amp; page.__post !== true) &#123; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">         &lt;%- partial('common/widget', &#123; position: 'right' &#125;) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+                &lt;% &#125; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">     &lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"> &lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"> &lt;/section&gt;</span></pre></td></tr></table></figure></li><li><p>修改 /source/css/style.styl </p> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">@media screen and (min-width: screen-widescreen)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    .is-1-column .container</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    .is-2-column .container</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">        max-width: screen-widescreen - 2 * gap</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">        width: screen-widescreen - 2 * gap</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">@media screen and (min-width: screen-fullhd)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    .is-2-column .container</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">        max-width: screen-fullhd - 2 * gap</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">        width: screen-fullhd - 2 * gap</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    .is-1-column .container</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">        max-width: screen-desktop - 2 * gap</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">        width: screen-desktop - 2 * gapp</span></pre></td></tr></table></figure></li><li><p>修改 /layout/layout.ejs</p> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"> &lt;% function main_column_class() &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">switch (column_count()) &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    case 1:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">        return &#39;is-12&#39;;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    case 2:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">        return &#39;is-8-tablet is-9-desktop is-9-widescreen&#39;;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    case 3:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">        return &#39;is-8-tablet is-8-desktop is-6-widescreen&#39;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">return &#39;&#39;;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">&#125; %&gt;</span></pre></td></tr></table></figure></li><li><p>修改 /layout/common/widget.ejs</p> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;% function side_column_class() &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">switch (column_count()) &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">case 2:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">    return &#39;is-4-tablet is-3-desktop is-3-widescreen&#39;;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">case 3:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    return &#39;is-4-tablet is-4-desktop is-3-widescreen&#39;;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">return &#39;&#39;;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">&#125; %&gt;</span></pre></td></tr></table></figure></li></ol><h2 id="文章图片居中"><a href="#文章图片居中" class="headerlink" title="文章图片居中"></a>文章图片居中</h2><p>最开始尝试了修改 source/js/main.js 和 layout/css/style.styl , 修改的内容也是基于水寒的博客，本地 hexo server没有问题，但是 hexo g -d 之后就总是出问题，最后还是老老实实<br>    <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;center&gt; </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">&lt;&#x2F;center&gt;</span></pre></td></tr></table></figure></p><h2 id="增加profile下面的-bio-可以放一点自己想说的话"><a href="#增加profile下面的-bio-可以放一点自己想说的话" class="headerlink" title="增加profile下面的 bio, 可以放一点自己想说的话"></a>增加profile下面的 bio, 可以放一点自己想说的话</h2><h3 id="实现效果"><a href="#实现效果" class="headerlink" title="实现效果"></a>实现效果</h3><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/screenshot 2019-11-16 at 11.47.59.png" height="40%" width="40%"></center><h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><p>修改 /layout/widget/profile.ejs, 在最后加上你想说的话<br>    <figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">        &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    &lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    &lt;% &#125; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+        &lt;hr&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+        &lt;p id="evan"&gt;修子也好，远野也好，对于情感世界发生的事，很难简单以对和错来衡量，在这样的世界里沉浮，飘落的是情感，不败的总是每年盛开的樱花。    --《情人》&lt;/p&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">&lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">&lt;/div&gt;</span></pre></td></tr></table></figure></p><h2 id="置顶文章"><a href="#置顶文章" class="headerlink" title="置顶文章"></a>置顶文章</h2><p>参考文章: <code>https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more</code></p><p><a href="https://github.com/removeif/hexo-theme-icarus-removeif/commit/a924e02916607ed351904e4833c541199807482d" target="_blank" rel="noopener">github commit history</a></p><h3 id="实现效果-1"><a href="#实现效果-1" class="headerlink" title="实现效果"></a>实现效果</h3><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/screenshot 2019-11-16 at 13.30.30.png" height="40%" width="40%"></center><h3 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h3><p>在每篇文章的top comment部分配置top字段，初始值是100，如果要置顶，需要设置为大于100的值，值越大越靠前。相等时，根据时间降序。具体设置如下<br>    <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">title: 一亩三分地自动签到脚本</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">top: 102</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">toc: true</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">recommend: 1 </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">date: 2019-09-19 22:10:43</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">thumbnail: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;removeif&#x2F;blog_image&#x2F;img&#x2F;2019&#x2F;20190919221611.png</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">tags: </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">categories:</span></pre></td></tr></table></figure></p><h3 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h3><p>修改 /layout/common/article.ejs<br>    <figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;% if (post.layout != 'page') &#123; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">&lt;div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    &lt;div class="level-left"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+       &lt;% if(post.top &gt; 100) &#123; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+       &lt;div class="level-item tag is-danger" style="background-color: #3273dc;"&gt;Pin&lt;/div&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+       &lt;%&#125; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">        &lt;time class="level-item has-text-grey" datetime="&lt;%= date_xml(post.date) %&gt;"&gt;&lt;%= date(post.date) %&gt;&lt;/time&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">        &lt;% if (post.categories &amp;&amp; post.categories.length) &#123; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">        &lt;div class="level-item"&gt;</span></pre></td></tr></table></figure></p><h2 id="文章底部文章详细信息显示以及推荐文章模块配置"><a href="#文章底部文章详细信息显示以及推荐文章模块配置" class="headerlink" title="文章底部文章详细信息显示以及推荐文章模块配置"></a>文章底部文章详细信息显示以及推荐文章模块配置</h2><p>参考文章: <code>https://removeif.github.io/2019/09/19/%E5%8D%9A%E5%AE%A2%E6%BA%90%E7%A0%81%E5%88%86%E4%BA%AB.html#more</code></p><p><a href="https://github.com/removeif/hexo-theme-icarus-removeif/commit/8fb8c23b8e3861fd56aa983f3eac8b0dbe18162d" target="_blank" rel="noopener">github commit history</a></p><h3 id="实现效果-2"><a href="#实现效果-2" class="headerlink" title="实现效果"></a>实现效果</h3><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/screenshot 2019-11-16 at 11.59.42.png" height="80%" width="80%"></center><h3 id="使用说明-1"><a href="#使用说明-1" class="headerlink" title="使用说明"></a>使用说明</h3><p>在每篇文章的top comment部分配置recommend值（必须大于0），越大越靠前，相等取最新的，最多取5条。具体设置如下<br>    <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">title: 一亩三分地自动签到脚本</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">top: 102</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">toc: true</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">recommend: 1 </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">date: 2019-09-19 22:10:43</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">thumbnail: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;removeif&#x2F;blog_image&#x2F;img&#x2F;2019&#x2F;20190919221611.png</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">tags: </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">categories:</span></pre></td></tr></table></figure></p><h3 id="配置-3"><a href="#配置-3" class="headerlink" title="配置"></a>配置</h3><ol><li><p>在 languages/xx.yml 中插入 recommend_posts，具体如下</p> <figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">widget:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    follow: 'Follow'</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    recents: 'Recent'</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+   recommend_posts: 'Recommend Posts'</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    links: 'Links'</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    tag_cloud: 'Tag Cloud'</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    catalogue: 'Catalogue'</span></pre></td></tr></table></figure><p>注意所使用的语言所对应的文件</p></li><li><p>修改 /layout/common/article.ejs </p> <figure class="highlight diff hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;div class="level-start"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    &lt;div class="level-item"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-deletion">-        &lt;span class="is-size-6 has-text-grey has-mr-7"&gt;#&lt;/span&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+        &lt;i class="fas fa-tags has-text-grey"&gt;&lt;/i&gt;&amp;nbsp;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">        &lt;%- list_tags(post.tags, &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">            class: 'has-link-grey ',</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">            show_count: false,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">            </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">..........</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    &lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">&lt;/div&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">&lt;% &#125; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+ &lt;!-- 部分参考自https://www.alphalxy.com/2019/03/customize-icarus/ --&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+ &lt;% if (!index &amp;&amp; post.layout === 'post' &amp;&amp; post.copyright !== false) &#123; %&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">    + &lt;ul class="post-copyright"&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">    + &lt;li&gt;&lt;strong&gt;本文标题：&lt;/strong&gt;&lt;a href="&lt;%= post.permalink %&gt;"&gt;&lt;%= page.title %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    + &lt;li&gt;&lt;strong&gt;本文作者：&lt;/strong&gt;&lt;a href="&lt;%= theme.url %&gt;"&gt;&lt;%= theme.author %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    + &lt;li&gt;&lt;strong&gt;本文链接：&lt;/strong&gt;&lt;a href="&lt;%= post.permalink %&gt;"&gt;&lt;%= post.permalink %&gt;&lt;/a&gt;&lt;/li&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    + &lt;li&gt;&lt;strong&gt;版权声明：&lt;/strong&gt;本博客所有文章除特别声明外，均采用 &lt;a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow" target="_blank"&gt;CC BY-NC-SA 4.0&lt;/a&gt; 许可协议。转载请注明出处！</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    + &lt;/li&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">    + &lt;/ul&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">    + &lt;br&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">    + &lt;%- _partial('widget/recommend_posts') %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">   + &lt;br&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-addition">+ br&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line"> + %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">&lt;% if (!index &amp;&amp; has_config('share.type')) &#123; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">&lt;%- _partial('share/' + get_config('share.type')) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line">&lt;% &#125; %&gt;</span></pre></td></tr></table></figure></li><li><p>/layout/widget 目录下添加 recommend_posts.ejs </p> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;span class&#x3D;&quot;is-size-6 has-text-grey has-mr-7&quot;&gt;#&amp;nbsp;&lt;%&#x3D; __(&#39;widget.recommend_posts&#39;) %&gt;&lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">&lt;br&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">&lt;% var i &#x3D; 1;posts.forEach(post &#x3D;&gt; &#123; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">&amp;nbsp;&lt;%&#x3D;i %&gt;.&lt;a href&#x3D;&quot;&lt;%- url_for((post.link?post.link:post.path)) %&gt;&quot; class&#x3D;&quot;is-size-6&quot; target&#x3D;&quot;_blank&quot;&gt;&lt;%&#x3D; post.title %&gt;&lt;&#x2F;a&gt;&lt;br&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">&lt;% i++;&#125;) %&gt;</span></pre></td></tr></table></figure></li><li><p>/layout/widget 目录下添加 recommend_posts.locals.js</p> <figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">module.exports &#x3D; (ctx, locals) &#x3D;&gt; &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">const &#123; has_config, get_config, get_thumbnail &#125; &#x3D; ctx;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">const &#123; posts &#125; &#x3D; ctx.site;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">if (!posts.length) &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">return null;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">const thumbnail &#x3D; !has_config(&#39;article.thumbnail&#39;) || get_config(&#39;article.thumbnail&#39;) !&#x3D;&#x3D; false;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">const _posts &#x3D; posts.filter((item, index, arr) &#x3D;&gt; item.recommend !&#x3D; undefined &amp;&amp; item.recommend &gt; 0).sort(&#39;recommend&#39;,-1).sort(&#39;recommend&#39;,-1).limit(5).map(post &#x3D;&gt; (&#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">link: post.link,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">path: post.path,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">title: post.title,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">date: post.date,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">thumbnail: thumbnail ? get_thumbnail(post) : null,</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; fix circular JSON serialization issue</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">categories: () &#x3D;&gt; post.categories</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">&#125;));</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">return Object.assign(locals, &#123; thumbnail, posts: _posts &#125;);</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">&#125;</span></pre></td></tr></table></figure></li></ol><h2 id="页脚访问人数显示修改"><a href="#页脚访问人数显示修改" class="headerlink" title="页脚访问人数显示修改"></a>页脚访问人数显示修改</h2><h3 id="实现效果-3"><a href="#实现效果-3" class="headerlink" title="实现效果"></a>实现效果</h3><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/screenshot 2019-11-17 at 18.25.58.png"></center><h3 id="配置-4"><a href="#配置-4" class="headerlink" title="配置"></a>配置</h3><p>修改 /layout/common/footer.ejs 卜算子部分.</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">&lt;% if (busuanzi) &#123; %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">                &lt;br&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">                &lt;span id&#x3D;&quot;busuanzi_container_site_uv&quot;&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">                &lt;!-- &lt;%- _p(&#39;plugin.visitor&#39;, &#39;&lt;span id&#x3D;&quot;busuanzi_value_site_uv&quot;&gt;0&lt;&#x2F;span&gt;&#39;) %&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">                &lt;br&gt; --&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">                &lt;span id&#x3D;&quot;busuanzi_container_site_pv&quot;&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">                    Visited by &lt;span id&#x3D;&quot;busuanzi_value_site_uv&quot;&gt;&lt;&#x2F;span&gt; users with &lt;span id&#x3D;&quot;busuanzi_value_site_pv&quot;&gt;&lt;&#x2F;span&gt; times</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">                &lt;&#x2F;span&gt;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">                &lt;% &#125; %&gt;</span></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一亩三分地自动签到脚本</title>
      <link href="/%E4%B8%80%E4%BA%A9%E4%B8%89%E5%88%86%E5%9C%B0%E8%87%AA%E5%8A%A8%E7%AD%BE%E5%88%B0%E8%84%9A%E6%9C%AC.html"/>
      <url>/%E4%B8%80%E4%BA%A9%E4%B8%89%E5%88%86%E5%9C%B0%E8%87%AA%E5%8A%A8%E7%AD%BE%E5%88%B0%E8%84%9A%E6%9C%AC.html</url>
      
        <content type="html"><![CDATA[<h1 id="脚本介绍"><a href="#脚本介绍" class="headerlink" title="脚本介绍"></a>脚本介绍</h1><p>前一段时间接触到了Surge，也间接接触到了js脚本的使用。群里很多人通过脚本实现了譬如天气提醒，百度贴吧签到，甚至是去除广告的功能，虽说之前没有接触过js，只写过一点python的脚本，但鉴于js脚本的使用范围实在太大，<a id="more"></a>这几天就动手学习了一点js的语法，修改了点脚本，前天花了点时间修改了作者 <a href="https://github.com/Neurogram-R" target="_blank" rel="noopener">Neurogram</a> 定点签到的脚本，适配了特定的html格式，以及增加了到期时间的显示，成就感还是蛮强的。由于到了申请季，很多同学都需要在比如一亩三分地的留学论坛上逛帖，所以出于兴趣，写了一亩三分地的自动签到脚本。</p><h2 id="Check-in-for-Shortcuts"><a href="#Check-in-for-Shortcuts" class="headerlink" title="Check in for Shortcuts"></a>Check in for Shortcuts</h2><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/IMG_593.JPG" height="60%" width="60%"></center><p>运行 Shortcuts 版时，需要先进入编辑页面，在URL_提交登陆模块填写账号信息，账号信息分为 <strong>用户名、密码、问题编号，问题答案</strong> 4个 DICTIONARY（字典），其中如果没有问题，<strong>问题编号写0，问题答案留空。</strong></p><h2 id="Check-in-for-Surge"><a href="#Check-in-for-Surge" class="headerlink" title="Check in for Surge"></a>Check in for Surge</h2><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/IMG_604.JPG" height="60%" width="60%"></center><ul><li><p><strong>填写账号信息</strong></p><pre><code>const accounts = [[&quot;username@xxx.com&quot;, &quot;xxx&quot;,&quot;x&quot;,&quot;xxxx&quot;]]</code></pre><p>  账号信息的填写要严谨按照代码示例的格式填写，内容顺序依次为 <strong>用户名、密码、问题编号，问题答案</strong>，4个内容用双引号””括起来，且不需要urlencode，直接原文显示。其中如果没有问题，<strong>问题编号写0，问题答案留空。</strong></p></li><li><p><strong>安装脚本</strong><br>  云端：自己的服务器或其他可生成文件直链的地方(github记得使用点raw进入直链)<br>  本地： iCloud / Dropbox 的 Surge 文件夹下</p></li><li><p><strong>配置脚本</strong></p><p>  进入 配置文件 的文本编辑模式，在 <code>[Script]</code> （如无 [Script]，编辑一个即可）下新建一行</p><pre><code>[Script]cron &quot;30 8 * * *&quot; script-path=checkin_1point.js</code></pre><p>  以上实例为 每天早上 8:30 运行存放于 本地的 checkin_1point.js 脚本（如脚本存放于云端，则 <code>script-path=脚本直链</code>）自定义触发时间配置使用的是 crontab 样式，api可参考 <a href="https://community.nssurge.com/d/33-scripting" target="_blank" rel="noopener">Scripting</a> 的介绍</p></li><li><p><strong>代码逻辑</strong></p><center><img src="https://cdn.jsdelivr.net/gh/NavePnow/blog_photo@private/Untitled.jpg" height="40%" width="40%"></center></li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>由于hash和cookie有关联，登陆的cookie有较长的使用期，而签到的cookie在每一次登陆之后都会更新，所以不能直接通过抓签到的包直接进行POST操作。同时在后期的测试过程中，如果想同时进行多账号的签到，由于登陆cookie在本机有保存，很可能出现提示了签到成功但账号实际没有签到成功的情况，所以建议大家只使用一个账号，或者签到完成后清除Safari的缓存，再进行另外一个账号的签到操作。<br>细心的同学看完代码会发现最后签到的函数正则里面包含了乱码字符，因为最后抓包之后返回的html是gbk编码的，处理起来不是特别方便，于是暂时就用了比较笨的方法进行了字符匹配。<br>这也是我第一个完整的写一个js脚本，业务逻辑方面包括函数，字典格式的使用或多或少存在不合理的地方，如果大家有更好的意见，欢迎给我联系。</p><ul><li><p><strong>反馈</strong></p><p>  💡 如果大家运行不了脚本或者运行出错，<a href="https://t.me/Leped_Bot" target="_blank" rel="noopener">反馈</a>的时候一定要带上报错的截图，有能力的同学在代码里面取消对应的<code>console.log(data)</code>的注释，并附上surge log的对应截图，感谢大家。</p></li></ul><h1 id="脚本下载"><a href="#脚本下载" class="headerlink" title="脚本下载"></a>脚本下载</h1><p>👉 <a href="https://www.icloud.com/shortcuts/36f6b3423b9c413386e70b44e1c11a21" target="_blank" rel="noopener">Check in for Shortcuts</a> (feat @wangfei021325)</p><p>👉 <a href="https://github.com/NavePnow/Profiles/blob/master/Scripts/checkin_1point.js" target="_blank" rel="noopener">Check in for Surge</a></p><h1 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h1><p>Telegram: <a href="https://t.me/Leped_Bot" target="_blank" rel="noopener">Leped_Bot</a></p><p>GitHub: <a href="https://github.com/NavePnow" target="_blank" rel="noopener">NavePnow</a></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>🔗 <a href="https://raw.githubusercontent.com/Neurogram-R/Surge/master/checkin.js" target="_blank" rel="noopener">Check-in Demo</a></p><p>🔗 <a href="https://www.notion.so/Check-in-0797ec9f9f3f445aae241d7762cf9d8b#a7821336c0bf414ba44f430f38147f5a" target="_blank" rel="noopener">Tutorial Demo</a></p><p>👨‍🏫 <a href="https://t.me/wangfei021325" target="_blank" rel="noopener">Advisor</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>柳烈的音乐专辑</title>
      <link href="/10-04-2019-%E6%9F%B3%E7%83%88%E7%9A%84%E9%9F%B3%E4%B9%90%E4%B8%93%E8%BE%91.html"/>
      <url>/10-04-2019-%E6%9F%B3%E7%83%88%E7%9A%84%E9%9F%B3%E4%B9%90%E4%B8%93%E8%BE%91.html</url>
      
        <content type="html"><![CDATA[<p>昨天在网上偶然间看到了一个帖子，名字是《柳烈的音乐专辑》，丁海寅和高金银主演，乍一看名字，感觉是跟奇迹唱片行一样的男女主因为音乐在一起的故事，而且丁海寅和高金银两位演员我蛮喜欢，正好也好久没看爱情片了，就直接在网上找了资源。不过说真的，凌晨 1 点开始，看完电影又在 b站上看了高金银的视频，粉了高金银的 ins，一直搞到了 5 点钟，算是 22 岁生日自己给自己的一份“大礼”吧(爆肝的开始)</p><a id="more"></a><p>讲真，我看别人评价这部电影，哭的都已经不行了，我全程看下来，还真的没有哭，感觉没有《现在去见你》那么催泪，不知道是不是我的情感殆尽，已经体会不到这种爱情带来的痛苦与温暖了。一个是被人误会犯下估计谋杀罪进入少管所看似辈子就已经没有任何希望的丁海寅饰演的角色（对不住了，我对名字实在不敏感），一个是刻苦学习想找一份工作但遇到经济危机难以生存的高金银饰演的角色，两个人的相遇是在丁海寅出狱的当天，因为韩国好像有出狱就一定要吃豆腐的原因，他进到了高金银打工的面包店里，询问是否有豆制品，这一天也恰好是柳烈的音乐专辑开播的第一天：1994年 10 月 1 日，一切都是新的开始，丁海寅抱着对生活新的期许，在这家店做起了兼职，仿佛忙碌着忙碌着就可以忘记之前的痛苦，但电影是不允许这样的，好的生活节奏被他一起出狱的朋友打破，一起出去喝酒结果和别人发生了口角，生活再次将他们打回原形，这一走就是 3 年，再次的重逢还是发生在面包店前，突然的偶遇让金高银重拾心中的花火，可第二天，丁海寅就要服役了。深夜的她打开电脑，给丁海寅注册了电邮，想他在军队的时候，也可以正常来往，结果，最终的电邮的密码却忘记告诉了他。服役的那么长时间里，邮箱里只有高金银的来信，没有一封是有回复的。丁海寅在休假的时候，有去过高金银之前租房子的地方，很聪明的猜到了邮箱的密码，两人的第三次相遇，这时时间到了 2000 年。仿佛是时间在捉弄两个人，丁海寅做兼职的地方出现了问题，约定的电话时间她被放了鸽子，而高金银自己也因为很多的不如意的地方而接近崩溃，不如意的工作，无聊而嘈杂的环境都让她无时无刻不在怀疑自己存在的价值，那天晚上，她哭着发了最后的一封邮件，说着“我也会在有好事发生的时候，再联系你”，电邮那头的他，也是对生活抱着怀疑的态度，犹豫的打下的字最后也只存在于垃圾箱中，就这样，两人再次失去了联系。时间到了 2005 年，高金银找到了自己如意的编辑工作，而且获得了满意的成就，丁海寅也和别人一起，做起了摄影相关的创业工作，巧的是，两人的工作室就是 1 层和 2 层的关系，于是，再次的相逢重新勾起了他们对于往事的回忆。同居生活，一起做饭，看书，睡觉，分享生活，但中间有一个细节，我当时看真的没有在意，看了别人的评论，我才发现的。当时高金银对丁海寅说：“我们结婚吧”，面对突然的问题，他一定是没有做好准备的，自己无法了却的过去和不确定的未来，哪一样都无法给她一个确定的答案，唯有夜里深深地拥抱才能给予他和她短暂的安全感。生活的冷水再次倒给了丁海寅，死去的朋友的 10 年祭到来了，作为“主犯”的他站在朋友家的门口，口口声声说自己并没有那么做，迎来的却是一句“就算知道也不知道”，这个世界仿佛总要去给每一件不好的事情找到一个看似合理的理由，即使大家都没有足够的理由去相信这是真的，仿佛是为了填补人们心中的创伤，也算是一种慰藉了。这个事情也恰好被金高银知道了，在丁海寅眼里，他只希望她能记住 1994 年之后的自己，因为过去的事情唯有少数人理解他，更多的人是不希望他能顺利的活在这个世界上的，即使他有多努力去改变自己。因为创业资金不足，他要搬离和金高银一起工作的地方，而且她的上司的油性骚扰有一种不可抗力，让丁海寅觉得她会跟上司一起生活。我第一遍看的时候，高金银上了上司的车真的以为他俩在一起了，后面看了影评才知道他们是一块去看了新的店面设计，是为了工作，我也算是长疏了一口气。而那一段丁海寅追汽车的桥段，仿佛是点燃了她心中仍有余温但快燃烧殆尽的火苗，和阿姨在一起的谈话也让她相信了他的难处以及想要努力生活的愿望。再一次也是电影最后的一个桥段，发生在了柳烈演播室的外面，高金银在电台节目里面听到了自己的名字，总有一种声音告诉她丁海寅就在电台的录制现场，于是，电影的最后，隔着一面玻璃，一个是 10 年都他妈没有任何变化甚至更加年轻的丁海寅，一个是拥有稳定工作又漂亮的高金银。</p><p>电影的题目是一档电台节目，两人因为电台节目的开始而相遇，因为电台的互诉新生，又因为电台而重新相逢。电影中的 bgm 用的也都是同时代韩国的爱情音乐，那首 Fin.K.L的永恒的爱一想起来，眼泪真的差点就忍不住了。电影看完又看了一遍他们两个在 Begin Again3 上的表演，嗓音真的绝了。10 年断断续续的相遇，都是努力生活的样子，都是对爱情充满了希望，真的很不错的爱情电影。最后推一首今天淘的歌作为结尾，金光石的《三十岁之际》<br><img src="https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0152.jpg" alt="IMG_0152"><br><img src="https://blogphoto-1257787992.cos.ap-beijing.myqcloud.com/2019/10/04/img0154.PNG" alt="IMG_0154"></p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Cest la vie - Sep 24, 2019</title>
      <link href="/Cest-la-vie-Sep-24-2019.html"/>
      <url>/Cest-la-vie-Sep-24-2019.html</url>
      
        <content type="html"><![CDATA[<p>今天还在跟我们班一起出国的人一起聊天，突然有一种作为倾听者的感觉。<a id="more"></a>我们班其实还有另外一个帅气小伙子，本来要出国，花了2年时间考英语， GT考了出来，最后选择了保研，选择了硬件，选择了国光的直博。当时听到这个消息，其实我有想到他的女朋友诶，有可能是为了爱情？今天和这个哥们聊天，好像有点确认了这个消息，然后这哥们就问我关于女朋友，出国的各种不确定性。或许是因为硬件条件？他说他不会在那边找的，想要在国内带一个过去，但又怕之后自己放弃这段爱情，然后就把问题抛给我了，我啷个知道咯，随缘吧？其实我有一条路的选择是，读完master工作，然后去新加坡，把孩子落户在那里，但这个旅程缺失了另外一个人，说真的，我也不知道她能在哪里被我遇到，愿意不愿意去新加坡，她家里愿意不愿意让她跟我去新加坡；或者说我有想法要读博，那以后的日子可就要更加想清楚了，当然我憧憬着lalaland里面现实的爱情故事，能遇到不能遇到就两说了。那哥们也是挺不容易的，自己背了债，想到美帝读phd回本，但又怕自己读完回来30+，看到自己的名字出现在非诚勿扰的名单里，资料里写着美国计算机博士的那种。我还记得很清楚，我们俩之前聊过这东西，大三的时候，他当时还是一脸不在乎，仿佛是梦中人，误以为自己找到了所有可行的道路。读完大学，大家都各奔东西了啊，结婚生孩，就仿佛是紧箍咒一般，永远去不掉，搞得你死去活来。昨天刚看了七毛的文章，心想真有这样的婆婆啊，卧槽，要是我妈这样，直接让她滚好了。话说回来，钱，爱情，生活，还有朋友，哪个是可以割舍的呢，都憧憬着甜甜的恋爱，说不定亲亲抱抱之后催债的电话就来了。活到这么大，真就是花父母的钱，我想作为父母，这或许就是教育投资吧，高投入，高风险的那种。生活啊，谁不是淌着一摊浑水艰难前行呢，当然有那种出生就比别人有更多的资源，房产加身，我是没有机会，我孩儿？先有个孩子再说吧。当他说到他家里对他出国态度的时候（国内保研多好，工作读博娶妻生子，安安稳稳，谁让你选择这条路了），我想到了大冰的书中说到的，年轻人，趁有活力，多闯一闯，多体验自己想要的生活，是啊，可如果失败了，真的就头破血流，落日黄花般模样了。朋友，加油啊，我真的不知道该怎么办，我也没经历过，所以我没给你一个明确的答复，到底是选择在国内还是国外。但总归，这就是生活啊，以梦为马，随处可栖？现在1:42了，手机打字是真的搞人，我也睡了。晚安。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Sep 17，2019 保研</title>
      <link href="/Sep-17%EF%BC%8C2019-%E4%BF%9D%E7%A0%94.html"/>
      <url>/Sep-17%EF%BC%8C2019-%E4%BF%9D%E7%A0%94.html</url>
      
        <content type="html"><![CDATA[<p>今天保研名单出来了，蛮多人都如释重负一般，纷纷在朋友圈欢送自己终于有学上了，当然在朋友圈，<a id="more"></a>还是有那么多人在面试的战场上处处碰壁。慢慢的，大学四年真的就要画上句号了，身边的同学考研的考研，保研的保研，出国的出国，还有最后真的就是混吃混喝的“大学生了”。每个人都忙碌着，憧憬着能有一个不错的未来。前几天班长让签放弃保研协议的时候，我还是很随意的表情，妈的，不就是一张纸，几句话的事情。可是今天的我，心情真的没有那天那么潇洒， 仿佛是自己养大的孩子被轻易的送走，而自己没有丝毫的伤心，这种感觉很奇妙，把大学四年的成绩赌在了出国的路上，放弃了国内所有的研究生资源。或许从今天开始，保研的那些同学就开始了暑假生活，迎接属于自己最后的一个暑假？而我们还是被 GT 困扰着，被申请束缚着。申请了大四下的新国大的项目其实就是想让自己逃离这个熟悉的环境，去一个相对陌生的地方学习，休息，生活。</p><p>保研的毕竟是少数，更多的是在图书馆奋笔读书备战的考研党，不知道他们的心里是什么感受，看着同学纷纷展示自己大学四年辛苦读书成功保研人生巅峰，而自己还在张宇肖秀荣的书本里苦苦挣扎。我们一起说要出国的一个同学没有签保研协议，在保研的名额里是最后一名，貌似只有国光实验室直博的名额供他选择，也不知道他会不会真香。4 年的生活真的就结束了，昨晚蛮多人还是辗转反则不知道能不能保研，今天就是安安稳稳躺在床上想着接下来的美好生活。日子总要过去啊，谁不是踩着泥泞的道路看着别人开着车驰骋在康庄大道上呢。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Sep 2, 2019</title>
      <link href="/Sep-2-2019.html"/>
      <url>/Sep-2-2019.html</url>
      
        <content type="html"><![CDATA[<p>昨天真的挺巧的，9 月1 号是我托福考试，也正好又梦见二姨了。<a id="more"></a>虽然梦早已经记不清了，但我早上起来，还是打开了笔记本写了 老二姨 三个字，因为我怕我忘记，我梦见了二姨。不知道我哭了没有，不知道你在那里过得怎么样，但真的，我好久没有梦见过你了，真的想再摸摸你的手，告诉你童童现在挺好的，也很努力，现在已经高三了，再过一年也跟我一样上了大学，到那个时候我也就毕业嘞，童童一定可以的。姥爷最近去拔牙了，好像是全拔了吧，这样就可以直接带假牙吃硬一点，好一点的东西了。说真的，我以后回家的时间真的很少了，那天三姨告诉你，你以后还有多长时间在郑州待着，是啊，真的就没有多少天了。感觉每个人都忙碌着，下半年挺忙的，GRE，托福，文书，申请，事情接踵而来，而我还没有完成一件事，托福学了不知道多久了，还是因为听力而没有实质的进步，GRE 因为做题没有多少，所以几斤几两也不是很清楚。身边挺多人都去考研了，天天 7 点多起床。忙点好啊，忙点就不会去想那些伤心的事了。你在那边记得多吃一点，hh，我最近还在减肥呢，不过等我瘦下去之后就去吃好吃的！那天我闻热水杯的热气，突然想起你呢，眼睛都突然湿掉了，hh。不管怎么样，都要身体健康嘞，也一定要开心呀。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的梦 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Google-BERT-on-fake_or_real-news-dataset</title>
      <link href="/Google-BERT-on-fake-or-real-news-dataset.html"/>
      <url>/Google-BERT-on-fake-or-real-news-dataset.html</url>
      
        <content type="html"><![CDATA[<p><strong>Description</strong>: Use Google BERT on fake_or_real news dataset with best f1 score: 0.986</p><a id="more"></a><h2 id="Showcase"><a href="#Showcase" class="headerlink" title="Showcase"></a>Showcase</h2><h3 id="1-Pipeline"><a href="#1-Pipeline" class="headerlink" title="1. Pipeline"></a>1. Pipeline</h3><p><img src="https://i.loli.net/2019/08/23/P8Seo5EvmpZfAOT.png" alt="Pipeline"></p><p>First, we got the raw text with title, text and label. Then we use some methods of data processing to operate the text. After the data processing, we put them into the Bert model to train the data, which includes the Bert itself and the Classifier, here I used the feed-forward neural network and add a softmax layer to normalize the output. In the end, we got the predication and other details.</p><h3 id="2-Part1-Data-processing"><a href="#2-Part1-Data-processing" class="headerlink" title="2. Part1: Data processing"></a>2. Part1: Data processing</h3><p>(1) <strong>Drop non-sentence</strong></p><pre><code>• Type1: http[s]://www.claritypress.com/LendmanIII.html• Type2: [email protected]• Type3: @EP_President #EP_President • Type4: **Want FOX News First * in your inbox every day? Sign up here.**• Type5: ☮️ 💚 🌍 etc</code></pre><p>(2) <strong>EDA methods</strong></p><pre><code>• Insert word by BERT similarity (Random Insertion)• Substitute word by BERT similarity (Synonym Replacement)</code></pre><p>AS for the first part, I use two methods: drop non-sentence and some EDA methods. I read some text within the fake_or_real news and I find that it contains various type of non-sentence, so I use the regular expression to drop them. And then, I use random insertion and synonym replacement to augment the text.</p><h3 id="3-Part2-Bert-Model"><a href="#3-Part2-Bert-Model" class="headerlink" title="3. Part2: Bert Model"></a>3. Part2: Bert Model</h3><p><img src="https://i.loli.net/2019/08/23/pFv1K86WUcafyDI.png" alt="Bert model"></p><p>As for the second part, we put the text which we got from the first part into the bert model. The Bert model uses 12 encode layers and finally classifier to get the output.</p><h3 id="4-Part3-Result"><a href="#4-Part3-Result" class="headerlink" title="4. Part3: Result"></a>4. Part3: Result</h3><p><img src="https://i.loli.net/2019/08/23/aGTYdfz2cul1pj3.png" alt="Result"></p><p>In the end, we combine different methods of data processing and u can see the f1 score from the chart. We get the best f1 score(0.986) from Cased text + drop sentence.</p><h3 id="5-Part4-Reference"><a href="#5-Part4-Reference" class="headerlink" title="5. Part4: Reference"></a>5. Part4: Reference</h3><p>(1) <strong>EDA</strong>: </p><pre><code>•Knowledge: https://towardsdatascience.com/these-are-the-easiest-data-augmentation-techniques-in-natural-language-processing-you-can-think-of-88e393fd610•Implemenation: https://github.com/makcedward/nlpaug</code></pre><p>(2) <strong>Can’t remove stopwords</strong>: </p><pre><code>•Deeper Text Understanding for IR with Contextual NeuralLanguage Modeling: https://arxiv.org/pdf/1905.09217•Understanding the Behaviors of BERT in Ranking : https://arxiv.org/pdf/1904.07531</code></pre><p>(3) <strong>Bert by Pytorch</strong>:</p><pre><code>•https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/</code></pre><p>(4) <strong>Bert Demo</strong>:</p><pre><code>https://github.com/sugi-chan/custom_bert_pipeline</code></pre><p>(5) <strong>Dataset</strong>:</p><pre><code>https://cbmm.mit.edu/sites/default/files/publications/fake-news-paper-NIPS.pdf</code></pre><p>I learn the EDA from the two web site and through two articles, I learn that we shouldn’t remove Stopwords which otherwise will destroy the context of sentence. The end is implementation of BERT with Pytorch and the Bert model I learned.</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><h3 id="1-Preparation"><a href="#1-Preparation" class="headerlink" title="1. Preparation"></a>1. Preparation</h3><h4 id="1-1-Set-parameters-and-install-and-load-required-package"><a href="#1-1-Set-parameters-and-install-and-load-required-package" class="headerlink" title="1.1 Set parameters and install and load required package"></a>1.1 Set parameters and install and load required package</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">### parameters Setting</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">par_cased = <span class="hljs-number">0</span> <span class="hljs-comment"># default cased, 0 means uncased</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">par_cleanup = <span class="hljs-number">1</span> <span class="hljs-comment"># default cleanup, 0 means non-cleanup</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">par_eda = <span class="hljs-number">0</span> <span class="hljs-comment"># default eda, 0 means non-eda</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">pip install pytorch_pretrained_bert nlpaug bert matplotlib sklearn librosa SoundFile nltk pandas</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function, division</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> lr_scheduler</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torchvision</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, models, transforms</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> time</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> os</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> copy</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> randrange</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve, auc</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> nlpaug.augmenter.char <span class="hljs-keyword">as</span> nac</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">#import nlpaug.augmenter.word as naw</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> nlpaug.flow <span class="hljs-keyword">as</span> naf</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> nlpaug.util <span class="hljs-keyword">import</span> Action</span></pre></td></tr></table></figure><h4 id="1-2-Set-tokenizer"><a href="#1-2-Set-tokenizer" class="headerlink" title="1.2 Set tokenizer"></a>1.2 Set tokenizer</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> pytorch_pretrained_bert <span class="hljs-keyword">import</span> BertTokenizer, BertModel, BertForMaskedLM</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># OPTIONAL: if you want to have more information on what's happening, activate the logger as follows</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> logging</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">logging.basicConfig(level=logging.INFO)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># Load pre-trained model tokenizer (vocabulary)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">if</span> par_cased ==<span class="hljs-number">1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'bert-base-cased'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'bert-base-uncased'</span>)</span></pre></td></tr></table></figure><h4 id="1-3-Define-Bert-Config"><a href="#1-3-Define-Bert-Config" class="headerlink" title="1.3 Define Bert Config"></a>1.3 Define Bert Config</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertLayerNorm</span><span class="hljs-params">(nn.Module)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, hidden_size, eps=<span class="hljs-number">1e-12</span>)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-string">"""Construct a layernorm module in the TF style (epsilon inside the square root).</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            """</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">            super(BertLayerNorm, self).__init__()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">            self.weight = nn.Parameter(torch.ones(hidden_size))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">            self.bias = nn.Parameter(torch.zeros(hidden_size))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">            self.variance_epsilon = eps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">            u = x.mean(<span class="hljs-number">-1</span>, keepdim=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">            s = (x - u).pow(<span class="hljs-number">2</span>).mean(<span class="hljs-number">-1</span>, keepdim=<span class="hljs-literal">True</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">            x = (x - u) / torch.sqrt(s + self.variance_epsilon)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-keyword">return</span> self.weight * x + self.bias</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertForSequenceClassification</span><span class="hljs-params">(nn.Module)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-string">"""BERT model for classification.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    This module is composed of the BERT model with a linear layer on top of</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    the pooled output.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    Params:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        `config`: a BertConfig class instance with the configuration to build a new model.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        `num_labels`: the number of classes for the classifier. Default = 2.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    Inputs:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            with the word token indices in the vocabulary. Items in the batch should begin with the special "CLS" token. (see the tokens preprocessing logic in the scripts</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            `extract_features.py`, `run_classifier.py` and `run_squad.py`)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            a `sentence B` token (see BERT paper for more details).</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            input sequence length in the current batch. It's the mask that we typically use for attention when</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            a batch has varying length sentences.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            with indices selected in [0, ..., num_labels].</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    Outputs:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        if `labels` is not `None`:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            Outputs the CrossEntropy classification loss of the output with the labels.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        if `labels` is `None`:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            Outputs the classification logits of shape [batch_size, num_labels].</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    Example usage:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    ```python</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    # Already been converted into WordPiece token ids</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">50</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    num_labels = 2</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">51</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    model = BertForSequenceClassification(config, num_labels)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">52</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    logits = model(input_ids, token_type_ids, input_mask)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">53</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"></span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">54</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    def __init__(self, num_labels=2):</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">55</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        super(BertForSequenceClassification, self).__init__()</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">56</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        self.num_labels = num_labels</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">57</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        if par_cased ==1:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">58</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            self.bert = BertModel.from_pretrained('bert-base-cased')</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">59</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        else:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">60</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            self.bert = BertModel.from_pretrained('bert-base-uncased')</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">61</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">62</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        self.classifier = nn.Linear(config.hidden_size, num_labels)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">63</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        nn.init.xavier_normal_(self.classifier.weight)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">64</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">65</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">66</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        pooled_output = self.dropout(pooled_output)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">67</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        logits = self.classifier(pooled_output)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">68</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"></span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">69</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        return logits</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">70</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    def freeze_bert_encoder(self):</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">71</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        for param in self.bert.parameters():</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">72</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            param.requires_grad = False</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">73</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">74</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">    def unfreeze_bert_encoder(self):</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">75</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        for param in self.bert.parameters():</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">76</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">            param.requires_grad = True</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">77</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"></span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">78</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">from pytorch_pretrained_bert import BertConfig</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">79</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"></span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">80</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">81</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">82</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"></span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">83</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">num_labels = 2</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">84</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">model = BertForSequenceClassification(num_labels)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">85</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"></span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">86</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"># Convert inputs to PyTorch tensors</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">87</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">#tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(zz)])</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">88</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string"></span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">89</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-string">#logits = model(tokens_tensor)</span></span></pre></td></tr></table></figure><h3 id="2-Dataset-Processing"><a href="#2-Dataset-Processing" class="headerlink" title="2. Dataset Processing"></a>2. Dataset Processing</h3><h4 id="2-1-Read-the-data-and-convert-label-into-binary-text"><a href="#2-1-Read-the-data-and-convert-label-into-binary-text" class="headerlink" title="2.1 Read the data and convert label into binary text"></a>2.1 Read the data and convert label into binary text</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">dat = pd.read_csv(<span class="hljs-string">'/data/fake_or_real_news.csv'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">dat.head()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">dat = dat.drop(columns=[<span class="hljs-string">'Unnamed: 0'</span>, <span class="hljs-string">'title_vectors'</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(dat)):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> dat.loc[i, <span class="hljs-string">'label'</span>] == <span class="hljs-string">"REAL"</span>: <span class="hljs-comment">#REAL equal 0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">        dat.loc[i, <span class="hljs-string">'label'</span>] = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">elif</span> dat.loc[i, <span class="hljs-string">'label'</span>] == <span class="hljs-string">"FAKE"</span>: <span class="hljs-comment">#FAKE equal 1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">        dat.loc[i, <span class="hljs-string">'label'</span>] = <span class="hljs-number">1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> dat.loc[i, <span class="hljs-string">'text'</span>] == <span class="hljs-string">""</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">        dat = dat.drop([i])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">dat.head()</span></pre></td></tr></table></figure><h4 id="2-2-Combine-the-title-and-text"><a href="#2-2-Combine-the-title-and-text" class="headerlink" title="2.2 Combine the title and text"></a>2.2 Combine the title and text</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">dat_plus = dat.copy()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">dat_plus[<span class="hljs-string">'title_text'</span>]=dat[<span class="hljs-string">'title'</span>]+<span class="hljs-string">'. '</span>+dat[<span class="hljs-string">'text'</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">dat_plus = dat_plus.drop(columns=[<span class="hljs-string">'title'</span>, <span class="hljs-string">'text'</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">dat_plus[<span class="hljs-string">'title_text'</span>]</span></pre></td></tr></table></figure><h4 id="2-3-Use-regular-expression-to-drop-non-sentence"><a href="#2-3-Use-regular-expression-to-drop-non-sentence" class="headerlink" title="2.3 Use regular expression to drop non-sentence"></a>2.3 Use regular expression to drop non-sentence</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> re</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cleanup</span><span class="hljs-params">(text)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> par_cased == <span class="hljs-number">0</span>: <span class="hljs-comment"># transfer into lower text if par_cased is false</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">        text = text.lower()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>,<span class="hljs-string">''</span>,text) <span class="hljs-comment"># drop http[s]://*</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">u"\\&#123;.*?&#125;|\\[.*?]"</span>,<span class="hljs-string">''</span>,text) <span class="hljs-comment"># drop [*]</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">u"\(\@.*?\s"</span>, <span class="hljs-string">''</span>, text) <span class="hljs-comment"># drop something like (@EP_President)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">u"\@.*?\s"</span>, <span class="hljs-string">''</span>, text) <span class="hljs-comment"># drop soething liek @EP_President</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">u"\#.*?\s"</span>, <span class="hljs-string">''</span>, text) <span class="hljs-comment"># drop something like #EP_President (maybe hashtag)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">u"\© .*?\s"</span>, <span class="hljs-string">''</span>, text) <span class="hljs-comment"># drop something like © EP_President</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">r'pic.tw(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+#]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span>,<span class="hljs-string">''</span>,text) <span class="hljs-comment"># drop pic.twitter.com/*</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">u"\*\*"</span>, <span class="hljs-string">''</span>, text) <span class="hljs-comment"># drop something like **Want FOX News First * in your inbox every day? Sign up here.**</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    text = re.sub(<span class="hljs-string">u"|•|☮️|💚|🌍|😍|♦|☢"</span>, <span class="hljs-string">''</span>, text) <span class="hljs-comment"># drop something like  and • etc</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span>(text)</span></pre></td></tr></table></figure><h4 id="2-4-Use-EDA-method-to-augment-the-text"><a href="#2-4-Use-EDA-method-to-augment-the-text" class="headerlink" title="2.4 Use EDA method to augment the text"></a>2.4 Use EDA method to augment the text</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> nlpaug.augmenter.char <span class="hljs-keyword">as</span> nac</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> nlpaug.augmenter.word <span class="hljs-keyword">as</span> naw</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> nlpaug.flow <span class="hljs-keyword">as</span> nafc</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> nlpaug.util <span class="hljs-keyword">import</span> Action</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> nltk</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">nltk.download(<span class="hljs-string">'punkt'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">if</span> par_cased ==<span class="hljs-number">1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    aug = naf.Sequential([</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">        naw.BertAug(action=<span class="hljs-string">"substitute"</span>, aug_p=<span class="hljs-number">0.8</span>, aug_n=<span class="hljs-number">20</span>,model_path=<span class="hljs-string">'bert-base-cased'</span>,tokenizer_path=<span class="hljs-string">'bert-base-cased'</span>),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">        naw.BertAug(action=<span class="hljs-string">"insert"</span>, aug_p=<span class="hljs-number">0.1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    ])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    aug = naf.Sequential([</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">        naw.BertAug(action=<span class="hljs-string">"substitute"</span>, aug_p=<span class="hljs-number">0.8</span>, aug_n=<span class="hljs-number">20</span>,model_path=<span class="hljs-string">'bert-base-uncased'</span>,tokenizer_path=<span class="hljs-string">'bert-base-uncased'</span>),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">        naw.BertAug(action=<span class="hljs-string">"insert"</span>, aug_p=<span class="hljs-number">0.1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    ])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">aug_text</span><span class="hljs-params">(text)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    text = aug.augment(text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span>(text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> sent_tokenize</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sentence_token_nltk</span><span class="hljs-params">(text)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">    sent_tokenize_list = sent_tokenize(text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span> sent_tokenize_list</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">eda_text</span><span class="hljs-params">(text)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> len(text) &lt; <span class="hljs-number">2</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span>(text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># split text into sentences</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line">    text = sentence_token_nltk(text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> len(text) &lt;= <span class="hljs-number">1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span>(text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> len(text) == <span class="hljs-number">2</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(text)):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line">                tmp_text = text[i]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line">            <span class="hljs-keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line">                tmp_text += text[i]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span>(tmp_text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># operate prior 3 sentences</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">3</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line">            tmp_text = text[i]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line">            tmp_text += text[i]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line">    zz = tokenizer.tokenize(tmp_text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># operate proper sentences</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">if</span> len(zz) &lt;= <span class="hljs-number">500</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment">#print(len(zz))</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">50</span></pre></td><td class="code"><pre><span class="line">        tmp_text = aug_text(tmp_text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">51</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-comment"># conbine prior 3 sentences and rest sentences</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">52</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(len(text)<span class="hljs-number">-3</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">53</span></pre></td><td class="code"><pre><span class="line">        tmp_text += text[j+<span class="hljs-number">3</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">54</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-keyword">return</span>(tmp_text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">55</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">56</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">if</span> par_eda == <span class="hljs-number">1</span>: <span class="hljs-comment"># use eda to operate sentences when par_eda is true</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">57</span></pre></td><td class="code"><pre><span class="line">  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(dat_plus[<span class="hljs-string">'title_text'</span>])):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">58</span></pre></td><td class="code"><pre><span class="line">      <span class="hljs-keyword">if</span> i%<span class="hljs-number">6</span> == <span class="hljs-number">1</span>:       </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">59</span></pre></td><td class="code"><pre><span class="line">          <span class="hljs-comment">#print(i)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">60</span></pre></td><td class="code"><pre><span class="line">          dat_plus[<span class="hljs-string">'title_text'</span>][i] = copy.deepcopy(eda_text(dat_plus[<span class="hljs-string">'title_text'</span>][i]))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">61</span></pre></td><td class="code"><pre><span class="line">          dat_plus[<span class="hljs-string">'title_text'</span>][i] = <span class="hljs-string">""</span>.join(dat_plus[<span class="hljs-string">'title_text'</span>][i])</span></pre></td></tr></table></figure><h3 id="3-Google-Bert"><a href="#3-Google-Bert" class="headerlink" title="3. Google Bert"></a>3. Google Bert</h3><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment">#F.softmax(logits,dim=1)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">if</span> par_cleanup == <span class="hljs-number">1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    X = dat_plus[<span class="hljs-string">'title_text'</span>].apply(cleanup)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    X = dat_plus[<span class="hljs-string">'title_text'</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">y = dat_plus[<span class="hljs-string">'label'</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">X_train = X_train.values.tolist()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">X_test = X_test.values.tolist()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">y_train = pd.get_dummies(y_train).values.tolist() <span class="hljs-comment"># convert to one-hot encoding</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">y_test = pd.get_dummies(y_test).values.tolist()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">max_seq_length = <span class="hljs-number">256</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">text_dataset</span><span class="hljs-params">(Dataset)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,x_y_list, transform=None)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">        self.x_y_list = x_y_list</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">        self.transform = transform</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self,index)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">        tokenized_title_text = tokenizer.tokenize(self.x_y_list[<span class="hljs-number">0</span>][index])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">if</span> len(tokenized_title_text) &gt; max_seq_length:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line">            tokenized_title_text = tokenized_title_text[:max_seq_length]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line">            </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line">        ids_title_text  = tokenizer.convert_tokens_to_ids(tokenized_title_text) <span class="hljs-comment">#tokens-&gt;input_ids</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line">        padding = [<span class="hljs-number">0</span>] * (max_seq_length - len(ids_title_text))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line">        ids_title_text += padding <span class="hljs-comment"># use padding to make the same ids</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">assert</span> len(ids_title_text) == max_seq_length</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-comment">#print(ids_title_text)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line">        ids_title_text = torch.tensor(ids_title_text)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">        label = self.x_y_list[<span class="hljs-number">1</span>][index] <span class="hljs-comment"># color        </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line">        list_of_labels = [torch.from_numpy(np.array(label))]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line">        </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span> ids_title_text, list_of_labels[<span class="hljs-number">0</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line">    </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">50</span></pre></td><td class="code"><pre><span class="line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">51</span></pre></td><td class="code"><pre><span class="line">        <span class="hljs-keyword">return</span> len(self.x_y_list[<span class="hljs-number">0</span>])</span></pre></td></tr></table></figure><h4 id="3-1-Create-data-dictionary"><a href="#3-1-Create-data-dictionary" class="headerlink" title="3.1 Create data dictionary"></a>3.1 Create data dictionary</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">batch_size = <span class="hljs-number">16</span> <span class="hljs-comment"># divide into 16 batches</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">train_lists = [X_train, y_train]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">test_lists = [X_test, y_test]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">training_dataset = text_dataset(x_y_list = train_lists )</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">test_dataset = text_dataset(x_y_list = test_lists )</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">dataloaders_dict = &#123;<span class="hljs-string">'train'</span>: torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-string">'val'</span>:torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">                  &#125;                </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">dataset_sizes = &#123;<span class="hljs-string">'train'</span>:len(train_lists[<span class="hljs-number">0</span>]),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">                <span class="hljs-string">'val'</span>:len(test_lists[<span class="hljs-number">0</span>])&#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="hljs-string">"cuda:0"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">print(device)</span></pre></td></tr></table></figure><h4 id="3-2-Define-the-train-model"><a href="#3-2-Define-the-train-model" class="headerlink" title="3.2 Define the train model"></a>3.2 Define the train model</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_model</span><span class="hljs-params">(model, criterion, optimizer, scheduler, num_epochs=<span class="hljs-number">25</span>)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">   since = time.time()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">'starting'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">   best_model_wts = copy.deepcopy(model.state_dict())</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">   best_loss = <span class="hljs-number">100</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">   best_f1 = <span class="hljs-number">0.978</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">   best_acc_test = <span class="hljs-number">0.96</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">   best_acc_train = <span class="hljs-number">0.96</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">   best_auc = <span class="hljs-number">0.96</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">   <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(num_epochs):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">       print(<span class="hljs-string">'Epoch &#123;&#125;/&#123;&#125;'</span>.format(epoch, num_epochs - <span class="hljs-number">1</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">       print(<span class="hljs-string">'-'</span> * <span class="hljs-number">10</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">       <span class="hljs-comment"># Each epoch has a training and validation phase</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">       <span class="hljs-keyword">for</span> phase <span class="hljs-keyword">in</span> [<span class="hljs-string">'train'</span>, <span class="hljs-string">'val'</span>]:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'train'</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line">               scheduler.step()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">               model.train()  <span class="hljs-comment"># Set model to training mode</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">else</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">               model.eval()   <span class="hljs-comment"># Set model to evaluate mode</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">           running_loss = <span class="hljs-number">0.0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">           </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line">           label_corrects = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">           TP = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">           TN = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line">           FN = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">           FP = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">           total_scores = []</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line">           total_tar = []</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-comment"># Iterate over data.</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">for</span> inputs, label <span class="hljs-keyword">in</span> dataloaders_dict[phase]:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment">#inputs = inputs</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment">#print(len(inputs),type(inputs),inputs)</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment">#inputs = torch.from_numpy(np.array(inputs)).to(device) </span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line">               inputs = inputs.to(device) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line">               label = label.to(device)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># zero the parameter gradients</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line">               optimizer.zero_grad()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># forward</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># track history if only in train</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-keyword">with</span> torch.set_grad_enabled(phase == <span class="hljs-string">'train'</span>):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-comment"># acquire output</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line">                   outputs = model(inputs)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line">                   outputs = F.softmax(outputs,dim=<span class="hljs-number">1</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line">                   </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">50</span></pre></td><td class="code"><pre><span class="line">                   loss = criterion(outputs, torch.max(label.float(), <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">51</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-comment"># backward + optimize only if in training phase</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">52</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'train'</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">53</span></pre></td><td class="code"><pre><span class="line">                       </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">54</span></pre></td><td class="code"><pre><span class="line">                       loss.backward()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">55</span></pre></td><td class="code"><pre><span class="line">                       optimizer.step()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">56</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">57</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># statistics</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">58</span></pre></td><td class="code"><pre><span class="line">               running_loss += loss.item() * inputs.size(<span class="hljs-number">0</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">59</span></pre></td><td class="code"><pre><span class="line">               label_corrects += torch.sum(torch.max(outputs, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == torch.max(label, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]) <span class="hljs-comment">#返回每一行中最大值的那个元素，且返回其索引（返回最大元素在这一行的列索引）</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">60</span></pre></td><td class="code"><pre><span class="line">               pred_choice = torch.max(outputs, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">61</span></pre></td><td class="code"><pre><span class="line">               target = torch.max(label, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">62</span></pre></td><td class="code"><pre><span class="line">               scores = pred_choice.cpu().tolist()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">63</span></pre></td><td class="code"><pre><span class="line">               tar = target.cpu().tolist()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">64</span></pre></td><td class="code"><pre><span class="line">               total_scores = total_scores + scores</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">65</span></pre></td><td class="code"><pre><span class="line">               total_tar = total_tar + tar</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">66</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">67</span></pre></td><td class="code"><pre><span class="line">               tmp_tp = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">68</span></pre></td><td class="code"><pre><span class="line">               tmp_tn = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">69</span></pre></td><td class="code"><pre><span class="line">               tmp_fn = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">70</span></pre></td><td class="code"><pre><span class="line">               tmp_fp = <span class="hljs-number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">71</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-keyword">if</span> pred_choice.numel()!= target.numel():</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">72</span></pre></td><td class="code"><pre><span class="line">                   print(<span class="hljs-string">"error"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">73</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(pred_choice.numel()):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">74</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-keyword">if</span> pred_choice[i] == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> target[i] == <span class="hljs-number">1</span> :</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">75</span></pre></td><td class="code"><pre><span class="line">                       tmp_tp = tmp_tp + <span class="hljs-number">1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">76</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-keyword">elif</span> pred_choice[i] == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> target[i] == <span class="hljs-number">0</span> :</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">77</span></pre></td><td class="code"><pre><span class="line">                       tmp_tn = tmp_tn + <span class="hljs-number">1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">78</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-keyword">elif</span> pred_choice[i] == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> target[i] == <span class="hljs-number">1</span> :</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">79</span></pre></td><td class="code"><pre><span class="line">                       tmp_fn = tmp_fn + <span class="hljs-number">1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">80</span></pre></td><td class="code"><pre><span class="line">                   <span class="hljs-keyword">elif</span> pred_choice[i] == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> target[i] == <span class="hljs-number">0</span> :</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">81</span></pre></td><td class="code"><pre><span class="line">                       tmp_fp = tmp_fp + <span class="hljs-number">1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">82</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># TP    both predict and label are 1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">83</span></pre></td><td class="code"><pre><span class="line">               TP += tmp_tp</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">84</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># TN    both predict and label are 0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">85</span></pre></td><td class="code"><pre><span class="line">               TN += tmp_tn</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">86</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># FN    predict 0 label 1</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">87</span></pre></td><td class="code"><pre><span class="line">               FN += tmp_fn</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">88</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment"># FP    predict 1 label 0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">89</span></pre></td><td class="code"><pre><span class="line">               FP += tmp_fp</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">90</span></pre></td><td class="code"><pre><span class="line">           epoch_loss = running_loss / dataset_sizes[phase]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">91</span></pre></td><td class="code"><pre><span class="line">           p = TP / (TP + FP)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">92</span></pre></td><td class="code"><pre><span class="line">           r = TP / (TP + FN)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">93</span></pre></td><td class="code"><pre><span class="line">           F1 = <span class="hljs-number">2</span> * r * p / (r + p)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">94</span></pre></td><td class="code"><pre><span class="line">           acc = (TP + TN) / (TP + TN + FP + FN)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">95</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">96</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-comment">### draw ROC curce</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">97</span></pre></td><td class="code"><pre><span class="line">           tpr = TP/(TP+FN)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">98</span></pre></td><td class="code"><pre><span class="line">           fpr = FP/(FP+TN)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">99</span></pre></td><td class="code"><pre><span class="line">           tnr = TN/(FP+TN)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">100</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">101</span></pre></td><td class="code"><pre><span class="line">           total_scores = np.array(total_scores)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">102</span></pre></td><td class="code"><pre><span class="line">           total_tar = np.array(total_tar)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">103</span></pre></td><td class="code"><pre><span class="line">           fpr, tpr, thresholds = roc_curve(total_tar, total_scores)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">104</span></pre></td><td class="code"><pre><span class="line">           roc_auc = auc(fpr, tpr) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">105</span></pre></td><td class="code"><pre><span class="line">           plt.title(<span class="hljs-string">'ROC'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">106</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> roc_auc &gt; best_auc:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">107</span></pre></td><td class="code"><pre><span class="line">               best_auc = roc_auc</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">108</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> epoch &lt; num_epochs <span class="hljs-number">-1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">109</span></pre></td><td class="code"><pre><span class="line">               plt.plot(fpr, tpr,<span class="hljs-string">'b'</span>,label=<span class="hljs-string">'AUC = %0.4f'</span>% roc_auc)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">110</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> epoch == num_epochs <span class="hljs-number">-1</span>:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">111</span></pre></td><td class="code"><pre><span class="line">               plt.plot(fpr, tpr, color=<span class="hljs-string">'darkorange'</span>, label=<span class="hljs-string">'MAX AUC = %0.4f'</span>% best_auc) </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">112</span></pre></td><td class="code"><pre><span class="line">           plt.legend(loc=<span class="hljs-string">'lower right'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">113</span></pre></td><td class="code"><pre><span class="line">           plt.plot([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],<span class="hljs-string">'r--'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">114</span></pre></td><td class="code"><pre><span class="line">           plt.ylabel(<span class="hljs-string">'TPR'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">115</span></pre></td><td class="code"><pre><span class="line">           plt.xlabel(<span class="hljs-string">'FPR'</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">116</span></pre></td><td class="code"><pre><span class="line">           plt.show()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">117</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">118</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-comment">#print('&#123;&#125; p: &#123;:.4f&#125; '.format(phase,p ))</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">119</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-comment">#print('&#123;&#125; r: &#123;:.4f&#125; '.format(phase,r ))</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">120</span></pre></td><td class="code"><pre><span class="line">           print(<span class="hljs-string">'&#123;&#125; F1: &#123;:.4f&#125; '</span>.format(phase,F1 ))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">121</span></pre></td><td class="code"><pre><span class="line">           print(<span class="hljs-string">'&#123;&#125; accuracy: &#123;:.4f&#125; '</span>.format(phase,acc ))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">122</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">123</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'val'</span> <span class="hljs-keyword">and</span> epoch_loss &lt; best_loss:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">124</span></pre></td><td class="code"><pre><span class="line">               print(<span class="hljs-string">'saving with loss of &#123;&#125;'</span>.format(epoch_loss),</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">125</span></pre></td><td class="code"><pre><span class="line">                     <span class="hljs-string">'improved over previous &#123;&#125;'</span>.format(best_loss))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">126</span></pre></td><td class="code"><pre><span class="line">               best_loss = epoch_loss</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">127</span></pre></td><td class="code"><pre><span class="line">               best_model_wts = copy.deepcopy(model.state_dict())</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">128</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment">#torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_loss.pth')</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">129</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> F1 &gt; best_f1:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">130</span></pre></td><td class="code"><pre><span class="line">               best_f1 = F1</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">131</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'val'</span> <span class="hljs-keyword">and</span> acc &gt; best_acc_test:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">132</span></pre></td><td class="code"><pre><span class="line">               best_acc_test = acc</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">133</span></pre></td><td class="code"><pre><span class="line">           <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'train'</span> <span class="hljs-keyword">and</span> acc &gt; best_acc_train:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">134</span></pre></td><td class="code"><pre><span class="line">               best_acc_train = acc</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">135</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment">#best_model_wts = copy.deepcopy(model.state_dict())</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">136</span></pre></td><td class="code"><pre><span class="line">               <span class="hljs-comment">#torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/bert_model_test_f1.pth')</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">137</span></pre></td><td class="code"><pre><span class="line">       print()</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">138</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">139</span></pre></td><td class="code"><pre><span class="line">   time_elapsed = time.time() - since</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">140</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">'Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s'</span>.format(</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">141</span></pre></td><td class="code"><pre><span class="line">       time_elapsed // <span class="hljs-number">60</span>, time_elapsed % <span class="hljs-number">60</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">142</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">"Parament setting: "</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">143</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">"cased: "</span>,par_cased)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">144</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">"cleanup: "</span>,par_cleanup)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">145</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">"eda: "</span>,par_eda)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">146</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">'Best train Acc: &#123;:4f&#125;'</span>.format(float(best_acc_train)))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">147</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">'Best test Acc: &#123;:4f&#125;'</span>.format(float(best_acc_test)))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">148</span></pre></td><td class="code"><pre><span class="line">   print(<span class="hljs-string">'Best f1 score: &#123;:4f&#125;'</span>.format(float(best_f1)))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">149</span></pre></td><td class="code"><pre><span class="line">   <span class="hljs-comment"># load best model weights</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">150</span></pre></td><td class="code"><pre><span class="line">   model.load_state_dict(best_model_wts)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">151</span></pre></td><td class="code"><pre><span class="line">   <span class="hljs-keyword">return</span> model</span></pre></td></tr></table></figure><h3 id="4-Final-output"><a href="#4-Final-output" class="headerlink" title="4. Final output"></a>4. Final output</h3><h4 id="4-1-Model-details"><a href="#4-1-Model-details" class="headerlink" title="4.1 Model details"></a>4.1 Model details</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">print(model)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">model.to(device)</span></pre></td></tr></table></figure><h4 id="4-2-F1-and-other-details"><a href="#4-2-F1-and-other-details" class="headerlink" title="4.2 F1 and other details"></a>4.2 F1 and other details</h4><figure class="highlight python hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">model_ft1 = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=<span class="hljs-number">10</span>)</span></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> FakeNews </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fake News 学习笔记（四）Project-Summary NLP-Summary</title>
      <link href="/Fake-News-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89.html"/>
      <url>/Fake-News-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89.html</url>
      
        <content type="html"><![CDATA[<p>转载大佬的博客，写的太牛逼了: [从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史]</p><a id="more"></a><h2 id="牢骚"><a href="#牢骚" class="headerlink" title="牢骚"></a>牢骚</h2><p>为期6周的项目终于结束了，从昨天晚上连夜训练跑代码到今天的 Presentation，虽然还有点紧张，但更多的是对项目的无奈，一组4 个人，连带 Q&amp;A 共 15min，平均下来每个人只有 2 分半的时间去展示自己做的东西。我实话说吧，就光 Bert，我都可以讲5min，一共 9 个组，难道就不能分来？？哪怕 3 个 3 个来也行，说起来我是真的烦，既然就是收钱那推荐信的项目了，掏了几万块钱就不能让这个钱花的值一点？其实我在小组分工方面是有点偏心的，我是想做文字处理的部分，而且最后选择了 Bert ，因为我想尝试一些不一样的东西，分类器之前大三下有上过课，虽然学的不是特别懂，但总算是有接触过，大学也不就是通识教育吗，我也没有希望我能有多么深入的学习，只希望我可以多学一点不会的东西，对于 NLP，我之前是一点都没有接触，当然原理性的东西就根本不可能知道，得知了项目是做关于自然语言处理的，我有蛮感兴趣，通过课上的学习，教授说了很多新兴的自然语言处理工具，其中就包括了 Bert，Bert 是 18 年底提出的知识，总感觉是我在大学学习的最新的知识了吧，相比于 11 年的 C++课本。。。不管了，知识是学给自己的，谁也偷不走，最后我还是总结一下我总的学到的知识吧。下面英文的部分是 “官方要求的项目总结”，就不再多说了，关于 Bert 的实现在另外一篇博客中有所展示，这里就不再一一赘述了。</p><h2 id="个人理解-从-Word2Vec-到-Bert"><a href="#个人理解-从-Word2Vec-到-Bert" class="headerlink" title="个人理解 从 Word2Vec 到 Bert"></a>个人理解 从 Word2Vec 到 Bert</h2><p>从最开始的 Word2Vec，到 GloVe，一直到最新的 Bert，无非是将文字转化为一个可以让机器识别的数据格式-矩阵。在最开始的模型中，也就是 Word 和 Glove，存在一个初始的矩阵，里面包含了该方法所用的文字 token 以及对应的 value，只需要将文字输入到模型中，即可得到每个文字所对应的向量值，也就是矩阵值(相乘)，这样就涉及到了如何得到初始矩阵的问题，Word 和 Glove 使用的方法当然是不同的，在我们项目小组中，我们尝试了用 Glove 代替 Word，并取得了较好的效果，但实质还是没有变化，存在的问题也是显然的。我们都知道每个单词在句子中的意思是依附于上下文的，就比如所有博客中提到的 Bank 这个单词，有银行和河岸的意思，所以将所有的意思用一个矩阵去表示显得有失偏颇，所以基于两者提出了更多的模型。</p><p>这就要提到 Elmo了（我学的不是很深，只是把大概的思想了解了一下）：根据上下文关系进行向量的生成，但是有别于前面两者，什么意思。Word 和 Glove 只是把初始矩阵给你，你并不可以改变其中的值，但是在 Elmo 中，应该是使用了迁移学习的思想，在初始矩阵的基础上根据训练集进行相关的更新，也就是矩阵值的更新，但是怎么生成初始矩阵我并没有怎么学习，Bert 倒是了解了一点，反正对于我来说，Elmo 的意义就是矩阵的动态更新，使得矩阵里面的值可以更贴切训练集中特定的文本。而且从训练效果看，具有很大的提高，说到这里，其实有点鄙视最开始的 Word 和 Glove 了，因为考虑的东西太少，这也是为什么我看到别人用 Word2Vec 可以达到0.9多正确率而直呼牛逼的原因。</p><p>从 Elmo 到 Bert，又是一个飞跃，当然不能否认，Bert 是基于前人的工作而提出的新型的模型，因为很多思想和前者都有很多相似之处，可以说是站在巨人的肩膀上看世界。Bert 采用了更为高效的网络结构-Transformer来更新初始矩阵, 以及巨大的预训练模型用来生成初始矩阵。同样是考虑到了文章的上下文关系，在 Bert 中共有 3 个不同的变量作为模型的输入，每个单词的 Embedding，位置的 Embedding 和句子的 Embedding（可以理解为和初始矩阵的乘积？），这些都是依附于初始矩阵得到的结果，但是有文章说 Word 的 Embedding 不依附于初始矩阵，那我就不是很懂了，anyway，有三种不同的输入进行网络模型。<br>在模型中只使用到了 Transformer 的 Encode 部分，具体的工作流程我就不懂了，反正经过了多层的 Encode，伴随着矩阵的更新（fune-tuning），最终可以得到很多个向量的结果，再加上 linear 和 softmax 层即可解决分类问题。有人会问了，那 Bert 是如何得到初始矩阵的。这就是 Bert 牛逼之处了，通过 mask 遮盖句子中的单词来训练单个单词，通过遮盖整个句子来训练整个句子，听过 Google 训练了整个 Wikipedia，真的牛逼。最终通过矩阵的更新得到了相应的结果。利用 Transformer 加上强大的与训练模型使得 Bert 脱颖而出，摘得了 NLP 的头牌，有人说 Bert 是 NLP 的顶峰，我看了几篇文章，一个是清华大学的，一个是斯坦福大学的，都是基于 Bert 的现有模型，要么是修改网络结构，要么是增加模型的输入以提高文章的 Contextual 属性，也得到了比初始模型更好的结果，可以说是炼丹成功的典范了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>说到这里，项目也就结束了，从最开始的打开 FakeNewsTutorial 到写下这最后一篇博客，完成了项目所有的工作，还8.23 下午赶了 Github 的 repo 作为展示，修改中介关于项目的细节，以及项目的总结书，感谢组员的配合和合作，我感觉我们在最后的 Pre 发挥的很好，希望给教授留下不错的印象吧，希望大家都好好努力，前程似锦。<br>                                                                ——王依凡 08/24/2019 华科东 11 栋</p><h2 id="Project-Summary"><a href="#Project-Summary" class="headerlink" title="Project Summary"></a>Project Summary</h2><h3 id="1-Contribution"><a href="#1-Contribution" class="headerlink" title="1. Contribution"></a>1. Contribution</h3><ol><li>My job in our group is to use Google Bert to classify the text and complete a pipeline.</li><li>Use various word processing methods for specific text to improve the final f1 score (0.986)</li><li>I arrange member’s work within the group and meeting time. Three rehearsals were completed through communication with members before the final pre.</li><li>Use my own server to build a python environment for team members</li><li>Check out the relevant information and code about Glove on the Internet and use it as a demo for other members.</li></ol><h3 id="2-Idea"><a href="#2-Idea" class="headerlink" title="2. Idea"></a>2. Idea</h3><ol><li>Specific text optimization for specific texts, such as fake_or_real_news.csv. Because Bert learns each sentence and the relationship between the sentences, using regular expressions to process non-sentences in the article (such as #hashtag) is necessary.</li><li>By checking out the relevant information, I learned that EDA (Easiest Data Augmentation) can improve the classification in the case of small text, so I tried two methods of EDA, one is Random Insertion, the other is Synonym Replacement)</li><li>Use Google Bert as a method of text classification. Google Bert is a cutting-edge approach to do NLP tasks with excellent and efficient classification and I use the Bert model with the softmax layer to complete text classification.</li></ol><h3 id="3-Something-I-want-to-share"><a href="#3-Something-I-want-to-share" class="headerlink" title="3. Something I want to share"></a>3. Something I want to share</h3><p>The initial idea of our group was to use Google Bert to generate vectors for downstream text classification tasks. However, through code testing, the output includes word vectors and sentence vectors with high dimensions and huge time consumption. Therefore, extracting vectors separately from the Bert model is a bit hard. If the vector can be extracted, the output also includes the word vector and the sentence vector, which is difficult to handle. Thus, we used the method mentioned in the article- adding softmax layer to finish the text. Then, I begin my work to use a completed Bert pipeline to finish the job. </p><p>At the beginning, I spent a lot of time collecting various information about Bert. Because Bert is based on the existing NLP model, I started with the history of NLP and learned the principles of multiple models, from GloVe to LSTM and ELMo, and finally to Bert. I finally got a glimpse of how Bert works and wrote a blog to my URL: <a href="https://nave.work">https://nave.work</a> . </p><p>In fact, I used the original data to feed the model and got a 0.98 f1 score, so how to optimize on this basis becomes a problem. I observed a lot of content that was not a sentence by observing the text, including the URL and #hashtag, so I used regular expressions to remove specific content to improve the f1 score, and finally reached the score of 0.986.</p><p>In the final training process, due to the tight time and heavy tasks, I rented 1080ti to complete all the tasks. Of course, I am satisfied with the final result. This is based on the powerful per-training model of Google Bert. Anyway, I gained a lot of knowledge through this project and learned a lot of debugging skills, I love NLP!! (Finally attach my Contribution chart:<br><img src="https://i.loli.net/2019/08/23/1dpgIJrTla3Uq6w.png" alt><br>and Github repo: <a href="https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference" target="_blank" rel="noopener">https://github.com/NavePnow/Google-BERT-on-fake_or_real-news-dataset#5-part4-reference</a></p>]]></content>
      
      
      <categories>
          
          <category> FakeNews </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fake News 学习笔记（三）Bert 负采样 Transformer</title>
      <link href="/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89Bert%20%E8%B4%9F%E9%87%87%E6%A0%B7%20Transformer.html"/>
      <url>/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89Bert%20%E8%B4%9F%E9%87%87%E6%A0%B7%20Transformer.html</url>
      
        <content type="html"><![CDATA[<h1 id="使用-Google-Bert-实现-Word-Embedding"><a href="#使用-Google-Bert-实现-Word-Embedding" class="headerlink" title="使用 Google Bert 实现 Word-Embedding"></a>使用 Google Bert 实现 Word-Embedding</h1><a id="more"></a><p>(由于组内分工，我和另外一位同学负责文字处理部分，所以这里主要介绍对于 Google Bert 的学习过程以及对于文字处理的一些细节)<br><strong>idea</strong>:</p><ol><li>将 cleaned 后的文本进行提取，如果 len(text)为 0，删掉 label</li><li>使用学习笔记二中提到的stemming lemmatizing技术，对文本进行处理(不知道结果怎么样)</li><li>to be continued</li></ol><h2 id="负采样"><a href="#负采样" class="headerlink" title="负采样"></a>负采样</h2><p>负采样通过使每一个训练样本仅仅改变一小部分的权重而不是所有权重。也就是对正确的一个输出单词up，选择5-20个不正确的单词low。在 Bert 中，首先给定的一个句子，下一句子正例（正确词），随机采样一句负例（随机采样词）,句子级上来做二分类（即判断句子是当前句子的下一句还是噪声），类似word2vec的单词级负采样。</p><h2 id="Transformer-模型结构"><a href="#Transformer-模型结构" class="headerlink" title="Transformer 模型结构"></a>Transformer 模型结构</h2><p><img src="https://i.loli.net/2019/08/11/DZd3vpK7OhyjgLX.png" alt="The Transformer Architecture"></p><p>如图所示，左边为encoder，右边为 decoder，具有高并行性的特点抱歉，现阶段本人能力有限，根本看不懂，反正牛逼就完事了，放上 link，万一以后回看呢。<br><a href="https://www.cnblogs.com/sxron/p/10035802.html" target="_blank" rel="noopener">Transformer arch.</a></p><h3 id="multi-head-attention"><a href="#multi-head-attention" class="headerlink" title="multi-head attention:"></a><strong>multi-head attention:</strong></h3><p>将一个词的vector切分成h个维度，求attention相似度时每个h维度计算。由于单词映射在高维空间作为向量形式，每一维空间都可以学到不同的特征，相邻空间所学结果更相似，相较于全体空间放到一起对应更加合理。比如对于vector-size=512的词向量，取h=8，每64个空间做一个attention，学到结果更细化。</p><h3 id="self-attention："><a href="#self-attention：" class="headerlink" title="self-attention："></a><strong>self-attention：</strong></h3><p>每个词位的词都可以无视方向和距离，有机会直接和句子中的每个词encoding。比如下面这个句子，每个单词和同句其他单词之间都有一条边作为联系，边的颜色越深表明联系越强，而一般意义模糊的词语所连的边都比较深。比如：law，application，missing，opinion。。。</p><h3 id="position-encoding"><a href="#position-encoding" class="headerlink" title="position encoding:"></a><strong>position encoding:</strong></h3><p>因为transformer既没有RNN的recurrence也没有CNN的convolution，但序列顺序信息很重要，比如你欠我100万明天要还和我欠你100万明天要还的含义截然不同。。。<br>　transformer计算token的位置信息这里使用正弦波，类似模拟信号传播周期性变化。这样的循环函数可以一定程度上增加模型的泛化能力。<br>　　但BERT直接训练一个position embedding来保留位置信息，每个位置随机初始化一个向量，加入模型训练，最后就得到一个包含位置信息的embedding（简单粗暴。。），最后这个position embedding和word embedding的结合方式上，BERT选择直接拼接。<br><img src="https://i.loli.net/2019/08/11/mnRFiSh8MkjHA5I.png" alt="Output"></p><h2 id="Google-Bert"><a href="#Google-Bert" class="headerlink" title="Google Bert"></a>Google Bert</h2><p>NLP任务分为两部分，其一是预训练产生<strong>词向量</strong>，其二是对词向量进行操作(下游 NLP 任务)</p><h3 id="预训练产生词向量"><a href="#预训练产生词向量" class="headerlink" title="预训练产生词向量"></a>预训练产生词向量</h3><p>相比于之前所用到的 word2vec，负采样从 word-level 升级到了 sentence-level ，从而可以获取句间关系。<br>Bert 使用双向encoding(模型在处理某一个词时，它能同时利用前面的词和后面的词两部分信息)，采用看不懂的 Transformer 结构，直接获得一整个句子的唯一向量表示。在 Transformer 结构中，最终的输入由下面 3 个embedding 组成。<br><img src="https://i.loli.net/2019/08/11/jdZ792TAniEIPhY.jpg" alt="Input"><br>EA 表示左句子，EB 表示右句子，CLS为特殊标记符，供 Transformer 对 CLS进行深度 embedding</p><p>###预训练模型和加载的训练集之间的关系<br>使用预先训练的模型，该模型已经在大型数据集上进行了训练，然后针对特定任务进行微调。</p><h3 id="下游-NLP-任务"><a href="#下游-NLP-任务" class="headerlink" title="下游 NLP 任务"></a>下游 NLP 任务</h3><p>在获得 Bert 词向量后，只需要在词向量上加入简单的分类器即可完成工作</p>]]></content>
      
      
      <categories>
          
          <category> FakeNews </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如父如子</title>
      <link href="/%E5%A6%82%E7%88%B6%E5%A6%82%E5%AD%90.html"/>
      <url>/%E5%A6%82%E7%88%B6%E5%A6%82%E5%AD%90.html</url>
      
        <content type="html"><![CDATA[<p>当金钱作为交换亲情的筹码</p><p>在穿梭城市的巴士上完成了本书的阅读，<a id="more"></a>大概3个多小时的时间，估计看完这部电影，也差不多需要这么长时间吧。</p><p>两个全然不同的家庭环境塑造了庆多、琉晴两个小孩迥异的性格，庆多懂得待人接物的道理，是家长眼里的“好孩子”，当然这和他的生长环境有关，父亲忙于工作，母亲也习惯了一个人安安静静地带孩子长大，严格的家规，三点一线的日常生活，所有的一切在庆多父母眼里早已成为理所应当的东西，但因为孩子抱错的事情，日常的生活节奏被打乱，庆多仿佛是导火索，点燃了这个破碎的家庭最后的救命稻草。琉晴出生在乡下，或许是身边都是小孩的缘故，他很会玩，当然，是父母眼里所谓的“调皮捣蛋”的孩子，没有那么多的规矩，小时候的琉晴充满了和父母快乐的回忆。他们两个因为血缘而需要被交换，不停的交换生活没有给琉晴带来多大的“进步”，反倒让庆多从原来的胆小，变得更加开朗活泼，同样的，庆多的家庭也因为这件事，从支离破碎的感情中逐渐找到属于自己的亲情。</p><p>庆多的父亲良多工作顺利，家庭“美满”，是外人只要提起就会羡慕的“好男人”形象，但他将对工作中的态度放到了日常的生活中，不允许自己和其他人有任何的过错。因为他对于工作有近乎痴迷的状态，这导致了他没有过多参与到庆多成长的片段中，进而，他没有理解庆多母亲绿的辛苦就显得有那么几分合理，当他知道了庆多不是自己的血肉的时候，他的态度开始变得冷淡，想象所有庆多做的不好的地方，嘴里冒出了那句另绿最为痛心的一句话“果然就是这样啊”，他把所有不好的东西都归结为绿的不对和血缘，把所有对的事情都当是理所应当，当他想用金钱收买琉晴，将两个孩子都占为己有的时候，绿开始意识到，在他眼里，一个母亲对一个孩子情感的付出是可以用金钱去交换的。</p><p>故事和我预想的结果不太一样，在我眼里，良多是不应该有孩子的，庆多和琉晴应该都属于他们，但这对于绿的打击太大了，太大了，她对于庆多倾注了太多太多感情，故事的最后庆多还是属于良多和绿，但这次，良多从琉晴身上，学到了很多为人父应该有的样子，同样都是父亲，同样都是一份工作，有些人，可以和孩子结下深厚的友情，而有些人，只是披着“父亲”的外衣罢了。</p><p>这是我完成的第三本是枝裕和的作品，我蛮喜欢他这种，近乎平淡的手法把生活描写的那么深入人心，如此真实的生活在现实生活中，哪怕在中国，恐怕也是每天都在都在上演吧。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>奇迹唱片行</title>
      <link href="/%E5%A5%87%E8%BF%B9%E5%94%B1%E7%89%87%E8%A1%8C.html"/>
      <url>/%E5%A5%87%E8%BF%B9%E5%94%B1%E7%89%87%E8%A1%8C.html</url>
      
        <content type="html"><![CDATA[<p>被许许多多微小又平凡的事物装点过的生活本身，一直鲜活而灿烂，闪耀到让我们无论如何，都看得到。<br>                             —smarttree（来自豆瓣）</p><a id="more"></a>                             <p>《奇迹唱片行》<br>估计这是2018年能完成的最后一本书了，当然我并没有指望在接下来的4天能看完一本书。</p><p>我蛮享受在城市穿梭的过程中仍有一段静默的时光，也很庆幸最后在地铁上完成了本书的阅读，上一次有同样的经历还是在飞机上。巧了，这次是送朋友去坐飞机。</p><p>这本书我蛮喜欢两个元素 1.音乐 2.自由（爱情这玩意暂且不谈）</p><p>或许佩格（男主母亲）并不能称之为一个“合格”的母亲，她没有给男主弗兰克足够的母爱？或者足够的照顾？但重要的是，他给了她欣赏音乐的技巧和和寻找音乐的能力。或许是因为从小的家教不同于传统的家庭，他的一生注定不会和普通人一样，仿佛他的一生，就为了追求人们所抛弃的东西：唱片。或说是，他所理解的音乐。他是一个优秀的聆听者，倾听他人的欢喜和苦楚，利用弗兰克自己所理解的音乐，推荐给别人，通过音乐治愈心灵。我看这本书，固定的bgm是Loving Vincent的OST，这个专辑很符合那种安静的氛围，不知道为什么，我总感觉歌和书是一样的，有很多的想象空间，能让我在图书馆哭成泪人，也能让我在困难的时候强挤出一个温暖的笑容。在看这本书的时候，我曾想到之前在国家大剧院听到的音乐会，那种震撼力，哪怕音质最高的音乐也难以望其项背。</p><p>自由，书中每个个体，心灵上都是自由的。哪怕是再平凡的生活，也能乐在其中，但社会变化太快了，一把火的功夫，烧毁了唱片行，断了弗兰克的梦，他也不得不为了生活，放弃了自己希望一辈子都能从事的工作-唱片行老板。若不是那短短的一次邂逅，如今的他早已过上“普通人”的生活。全书仿佛就是围绕两个词 CD和黑胶唱片 来刻画弗兰克的人生，他崇尚唱片，认为CD没有灵魂，哪怕是所有的零售商断了他的财路，他也为了心中的梦想，一点一点努力着。很快的，CD被数字化的生活所取代，人们纷纷戴上耳机，只要手指轻轻一动，想要播放的音乐就自动流进耳朵。本书的最后，得到他人帮助后的弗兰克，重新经营起了唱片行，可这次，他的身边多了一个可以一直陪伴他的人。</p><p>不知道为什么，感觉这本书有些地方和《岛上书店》蛮像，或许因为书和音乐？</p><p>不管了，又一段精彩的旅程画上句号，地铁快到站了，我要收拾收拾下车了。</p><p>以下内容摘自《奇迹唱片行》<br>黑胶唱片是有生命的，你只能等待。</p><p>各种不同的音乐之中都可以看见不同的画面，只要你肯驻足聆听。</p><p>机会已失，就像错过火车或某种更重要的东西一样——某种再也不会出现的东西。</p><p>二十一年的岁月可以浓缩成多么简短的字句啊。这究竟是好事还是坏事呢？也或许人生本就是这样。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>1987</title>
      <link href="/1987.html"/>
      <url>/1987.html</url>
      
        <content type="html"><![CDATA[<p>同《出租车司机》一样，该影片反映的是韩国人民为争取民主而做出的牺牲。真的感谢TSKS韩剧社…能翻译出这么优秀的电影作品…这种心潮澎湃的感觉…很久没有出现了<br>imdb8.2分 值得观看</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/hello-world.html"/>
      <url>/hello-world.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a><a id="more"></a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="hljs-string">"My New Post"</span></span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo server</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo generate</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash hljs"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>The Post</title>
      <link href="/The-Post.html"/>
      <url>/The-Post.html</url>
      
        <content type="html"><![CDATA[<p>历史题材电影，涉及美国新闻自由、反战等话题。。。。电影讲述的是在“水门事件”的前夕，一群新闻媒体人为了捍卫新闻的原则，不惜舍弃前途而与尼克松政府对抗的故事。《The Post》和电影《1987》一样，虽说时代背景不同，但是都反映了新闻工作者对于个人安危和国家存亡的方面的取舍问题。</p><a id="more"></a><p>摘录电影里面最后一句：<br>The founding fathers gave the free press, the protection it must have to fulfill its essential role in our democracy. The press was to serve the governed, not the governors.</p><p>imdb7.4分 斯皮尔伯格导演的电影还是值得观看的</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>追风筝的人</title>
      <link href="/%E8%BF%BD%E9%A3%8E%E7%AD%9D%E7%9A%84%E4%BA%BA.html"/>
      <url>/%E8%BF%BD%E9%A3%8E%E7%AD%9D%E7%9A%84%E4%BA%BA.html</url>
      
        <content type="html"><![CDATA[<p>寒假书单3<br>生活在一个等级分明的地方，究竟是什么滋味</p><a id="more"></a><p>故事的发展很像是一个人的救赎，甚至书中的某些片段都与电影《穿条纹睡衣的男孩》极为相似-宗教和种族对于一群人一生的影响。坦诚来讲，我对于伊斯兰文化了解的少之又少，这本书对于我来说也算是科普性质的书籍了。如果你对于伊斯兰教感兴趣的话，不妨去阅读一番，全书时长近7个小时，耐着性子读下去吧。</p><p>“也许每个人心中都有一个风筝，无论它意味着什么，让我们勇敢的追”——翻译 李继宏</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>岛上书店</title>
      <link href="/%E5%B2%9B%E4%B8%8A%E4%B9%A6%E5%BA%97.html"/>
      <url>/%E5%B2%9B%E4%B8%8A%E4%B9%A6%E5%BA%97.html</url>
      
        <content type="html"><![CDATA[<p>寒假书单2<br>独自生活的真正难处在于没人在乎你是否心烦意乱</p><a id="more"></a><p>昨天的托福课实在上得心烦意乱，甚至在阅读《岛上书店》时都产生了一种负面的情感。不管怎么样，我还是完成了对这本书的阅读。《岛上书店》是关于“爱与被爱”的故事，书中关于爱情的观点我在互联网中见过相似的描写，但还没有做到亲身经历，所以暂不评论。所以对于这本书，我能感受到的最大的遗憾就是。书中提到的所有书目，我基本上没有看过一本，作者对于情感的把握，很多是依附于其他小说的角色上面，所以说，我还有很长一段路要走。最后引用书中小女孩对纸质书的形容结束这段评论    （东西）</p><p>“爸爸的香皂，青草，大海，厨房里的餐桌，及奶酪。”</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>房思琪的初恋乐园</title>
      <link href="/%E6%88%BF%E6%80%9D%E7%90%AA%E7%9A%84%E5%88%9D%E6%81%8B%E4%B9%90%E5%9B%AD.html"/>
      <url>/%E6%88%BF%E6%80%9D%E7%90%AA%E7%9A%84%E5%88%9D%E6%81%8B%E4%B9%90%E5%9B%AD.html</url>
      
        <content type="html"><![CDATA[<p>寒假书单1<br>痛苦的际遇是如此难以分享，好险这个世界还有文学。</p><a id="more"></a><p>我是知道了本书作者自杀的消息后才开始了解这本书，仿佛是为了进行某种宗教仪式一样，迫使我完成对本书的阅读。本书讲述的内容大家可以百度，我就不愿再次揭开林的痛苦，如果说你对本书有兴趣，那你可以继续往下看了：</p><p>我不知道初恋对于一个女生的重要性，也当然不知道，一个中年有家室的老师的花言巧语和行为上的放纵竟能对一个女生的影响会那么大。这本书就像是梦魇一样，折磨着我。</p><p>老师们说道“我们会老去，可她们不会老去”，无限的美好的心灵在老师眼下就只是还没有失去并等待剥夺的童真的美丽而又充满诱惑的少女。房思琪的爱情和人生在高中就静止了；另外一个女生在网站上哭诉，收获的却是网友们的千刀万剐，“要爽就直说”的句子我不是没有在中国的网站上看到过。房思琪的“死”不只是由简简单单一个老师的功劳，而是整个社会对于性的回避和对性暴力的漠视所造成的。</p><p>看完整本书，我翻看了林的fb，有句话我蛮触动 “我突然发现我对B做的最残忍的事情就是让他明白，身为重度精神病患者的伴侣，他无论如何都无法让我真正幸福”</p><p>如果说你是一名男生，我会告诉你，这本书的内容会有画面感，产生生理作用不要觉得害羞，因为我就是；如果是一名女生，我要说一声抱歉，因为我是不愿让你去看清这个世界的黑暗面的。</p><p>东西写到这里也要结束了。有科学文章表明，人们在网上看长篇东西是呈F形状的，不为内容，也要看了结尾。既然这是最后，那我希望你，能好好对待每一场恋爱，对以前真心爱过的人说声“我真的有爱过你”…以及，对那些社会上的“幸存者”抱以宽容的态度，有些痛你是不会经历的……..anyway我又多了一个再去一次台湾的理由</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Fake News 学习笔记（二） one-hot-coding Stem-and-Lem Word2Vec</title>
      <link href="/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%20one-hot-coding%20Stem-and-Lem%20Word2Vec.html"/>
      <url>/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%20one-hot-coding%20Stem-and-Lem%20Word2Vec.html</url>
      
        <content type="html"><![CDATA[<h1 id="One-hot-coding-独热编码"><a href="#One-hot-coding-独热编码" class="headerlink" title="One-hot coding(独热编码)"></a>One-hot coding(独热编码)</h1><a id="more"></a><p>果然又是 1个半小时只记住专有名字的课程。<br><strong>target</strong>:将非数值类型量化数值类型，以便于模型的输入<br><strong>process</strong>:N位状态寄存器来对N个状态进行编码就是将所有状态排列，具有哪些状态就将状态进行标记<br><strong>instance</strong>:<br>face = [‘handsome’,’ugly’]<br>stature = [‘tall’,’middle’,’short’]<br>country = [‘Chinese’,’American,’Japan’,’korea’]<br>共有 9 种状态，用 9 位数字表示。<br>[‘handsome’,’tall’,’Japan’] 表示为 101000010<br>[‘ugly’,’short’,’Japan’] 表示为 010010010</p><h1 id="Bag-of-words"><a href="#Bag-of-words" class="headerlink" title="Bag of words"></a>Bag of words</h1><p>不考虑单词在文章中的顺序，只考虑单词在文章中的词频率(occurence)</p><h1 id="Stemming-and-Lemmatizing"><a href="#Stemming-and-Lemmatizing" class="headerlink" title="Stemming and Lemmatizing"></a>Stemming and Lemmatizing</h1><p><strong>cliche</strong>:normalize different forms of the same word to a single root token before indexing<br>stemming can often create non-existent words, whereas lemmas are actual words.</p><h2 id="Stemming"><a href="#Stemming" class="headerlink" title="Stemming"></a>Stemming</h2><p>找词根(chops off the endings of different forms of words) “derivational affixes”<br><strong>questions</strong>:some decorations like ir or un, some of them will be deleted? eg:unchange to change (not implentation)</p><h2 id="Lemmatizing"><a href="#Lemmatizing" class="headerlink" title="Lemmatizing"></a>Lemmatizing</h2><p>根据词典找单词本身的形式 eg: saw to see</p><h1 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h1><p><strong>cliche</strong>:Word2Vec使用一层神经网络将one-hot（独热编码）形式的词向量映射到分布式形式的词向量。使用了Hierarchical softmax， negative sampling等技巧进行训练速度上的优化.<br>在前文中介绍了 one-hot coding，但是由于英文单词词汇量巨大的特征，每一个单词都对应上文例子中的 feature，可想而知，会造成维度灾难和数据稀疏的问题（妈的，上课这个东西讲了近 40min），所以使用Word2Vec能够解决这些问题。</p><h2 id="TD-IDF"><a href="#TD-IDF" class="headerlink" title="TD-IDF"></a>TD-IDF</h2><p>评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度，TF意思是词频(Term Frequency)，IDF意思是逆文本频率指数(Inverse Document Frequency)。</p><h2 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h2><p>把一些输入映射为0-1之间的实数，并且归一化保证和为1</p><h2 id="CBOW-Continous-Bag-of-Words"><a href="#CBOW-Continous-Bag-of-Words" class="headerlink" title="CBOW(Continous Bag of Words)"></a>CBOW(Continous Bag of Words)</h2><p>已知词w上下文context(w)前提下，预测当前词w</p><h2 id="skip-gram"><a href="#skip-gram" class="headerlink" title="skip-gram"></a>skip-gram</h2><p>已知当前词w，预测其上下文context(w)</p><h2 id="distributed-representation"><a href="#distributed-representation" class="headerlink" title="distributed representation"></a>distributed representation</h2><p>通过训练得到每个词k 维实数向量，通过词间距离来计算词间相似度。<br>通过训练，将每一个词映射到一个固定长度的短向量中，把词的信息分布到各个分量中，并且语义相近的词向量见距离越近</p><h2 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h2><p>size: Number of dimensions for the word embedding model<br>window: Number of context words to observe in each direction<br>min_count: Minimum frequency for words included in model<br>sg (Skip-Gram): ‘0’ indicates CBOW model; ‘1’ indicates Skip-Gram<br>alpha: Learning rate (initial); prevents model from over-correcting, enables finer tuning<br>iterations: Number of passes through dataset<br>batch_words: Number of words to sample from data during each pass</p>]]></content>
      
      
      <categories>
          
          <category> FakeNews </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fake News 学习笔记（一）分类器，f1 score</title>
      <link href="/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%86%E7%B1%BB%E5%99%A8%EF%BC%8Cf1%20score.html"/>
      <url>/Fake%20News%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E5%88%86%E7%B1%BB%E5%99%A8%EF%BC%8Cf1%20score.html</url>
      
        <content type="html"><![CDATA[<h2 id="NFL-data"><a href="#NFL-data" class="headerlink" title="NFL data"></a>NFL data</h2><p>美国职业橄榄球大联盟（National Football League，简称NFL）<a id="more"></a><br>你妹的，这教授我佛了。</p><h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>在第一节课中，x 轴代表该队触地得分的次数，y 轴代表该队是否胜利，输为 0，赢为 1，不使用线性回归的原因是该结果的输出为二分类问题，不需要数据的连续性，只需要输出 0 和 1 即可，同时该问题不是简单地线性问题，即很难用一条直线直接模拟该队触地得分次数与输赢的关系，同时受离群值的影响（当 x 值特别大，超过了正常的范围，就会影响正常值的分类），使用线性回归有很大的几率分类错误，所以所以使用逻辑回归方法进行分类。</p><p>逻辑回归使用 Sigmoid 函数，将函数的输入范围是负无穷到正无穷的定义域规定为 0-1 之内的范围，这样就解决了由于离群值对于阈值的影响作用。</p><h2 id="参数定义（用于-F1-score-计算）"><a href="#参数定义（用于-F1-score-计算）" class="headerlink" title="参数定义（用于 F1 score 计算）"></a>参数定义（用于 F1 score 计算）</h2><p><strong>True Positives (TP)</strong>: Correct positive predictions<br>预测 yes，真实 yes<br><strong>False Positives (FP)</strong>: Incorrect positive predictions (false alarm)<br>预测 yes，真实 no<br><strong>True Negatives (TN)</strong>: Correct negative predictions<br>预测 no，真实 no<br><strong>False Negatives (FN)</strong>: Incorrect negative predictions (a miss)<br>预测 no，真实 yes</p><h2 id="F1-score"><a href="#F1-score" class="headerlink" title="F1 score"></a>F1 score</h2><p>用来衡量二分类模型精确的一种指标<br><strong>精确率</strong>：TP/所有预测的 yes（所有预测 yes 中真实为 yes 的比率）<br><strong>召回率</strong>：TP/所有真实的 yes（所有真实 yes 中预测为 yes 的比率）<br><strong>F1 score</strong>：2/(1/P+1/C)=2TP(2TP+FN+FP)</p><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>利用 if-then 原则，按照树状结构的特点，叶节点表示其分类标记，非叶节点表示其各个 feature，利用 feature 进行匹配，直至找到最符合数据的分类。</p><h2 id="随机森林（Random-Forests）"><a href="#随机森林（Random-Forests）" class="headerlink" title="随机森林（Random Forests）"></a>随机森林（Random Forests）</h2><p>包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。，随机森林对回归的结果在内部是取得平均</p><p>在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。</p><h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>XGBoost是boosting算法的其中一种。Boosting算法的思想是将许多弱分类器集成在一起形成一个强分类器。因为XGBoost是一种提升树模型，所以它是将许多树模型集成在一起，形成一个很强的分类器。而所用到的树模型则是CART回归树模型。</p>]]></content>
      
      
      <categories>
          
          <category> FakeNews </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>痛苦的MARL(三)</title>
      <link href="/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%B8%89.html"/>
      <url>/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%B8%89.html</url>
      
        <content type="html"><![CDATA[<h1 id="多智能体强化学习入门（三）——MFMARL算法（Mean-Field-Multi-Agent-RL）"><a href="#多智能体强化学习入门（三）——MFMARL算法（Mean-Field-Multi-Agent-RL）" class="headerlink" title="多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）"></a>多智能体强化学习入门（三）——MFMARL算法（Mean Field Multi-Agent RL）</h1><a id="more"></a><p><strong>Idea</strong>:将传统的多智能体算法（每个智能体都需考虑其他所有智能体的动作以及状态得到联合动作值函数）替换成一种近似假设（其他所有智能体对其产生的作用可以用一个均值替代）–MFT 平均场理论<br>Based on MFT, there are two basic algoritms: MFQ &amp; MFAC. （分别是对 Q learning 和 AC 算法的改进）</p><h2 id="1-Mean-Field-MARL"><a href="#1-Mean-Field-MARL" class="headerlink" title="1. Mean Field MARL"></a>1. Mean Field MARL</h2><p><strong>Idea</strong>: 将 Q 函数中的参数调整为只包含邻居之间相互作用的形式：<br>$$<br>    Q_j(s,a)=\frac{1}{N_j}\sum <em>{k\epsilon N</em>{(j)}}Q_j(s,a_j,a_k)<br>$$<br>其中$N_j$表示邻居节点个数，状态信息 s 为全局信息。</p><h3 id="1-Mean-Field-近似"><a href="#1-Mean-Field-近似" class="headerlink" title="1. Mean Field 近似"></a>1. Mean Field 近似</h3><h3 id="2-算法设计"><a href="#2-算法设计" class="headerlink" title="2. 算法设计"></a>2. 算法设计</h3><p>MF-Q + MF-AC Algorithm</p><h4 id="1-MF-Q"><a href="#1-MF-Q" class="headerlink" title="1. MF-Q"></a>1. MF-Q</h4><h4 id="2-MFAC"><a href="#2-MFAC" class="headerlink" title="2. MFAC"></a>2. MFAC</h4>]]></content>
      
      
      <categories>
          
          <category> MARL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>痛苦的MARL(二)</title>
      <link href="/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%BA%8C.html"/>
      <url>/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%BA%8C.html</url>
      
        <content type="html"><![CDATA[<h1 id="多智能体强化学习-二-基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）"><a href="#多智能体强化学习-二-基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）" class="headerlink" title="多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）"></a>多智能体强化学习(二) 基础算法（MiniMax-Q，NashQ，FFQ，WoLF-PHC）</h1><a id="more"></a><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>再多智能体强化学习中，需要多 agent 在与环境交互过程中不断学习每个状态的奖励值 Q函数，再通过 Q函数来学习得到最优纳什策略。<br><strong>合理性</strong>（rationality）是指在对手使用一个恒定策略的情况下，当前智能体能够学习并收敛到一个相对于对手策略的最优策略。</p><p><strong>收敛性</strong>（convergence）是指在其他智能体也使用学习算法时，当前智能体能够学习并收敛到一个稳定的策略。通常情况下，收敛性针对系统中的所有的智能体使用相同的学习算法。</p><h2 id="2-Minimax-Q算法"><a href="#2-Minimax-Q算法" class="headerlink" title="2. Minimax-Q算法"></a>2. Minimax-Q算法</h2><p><strong>Condition</strong>: 两个玩家的零和随机博弈(eg.抛硬币)<br><strong>Idea</strong>: 利用 Qlearning 的方法更新Q值<br><strong>Algorithm</strong>:<br><img src="https://pic2.zhimg.com/80/v2-e907b291d3ec2e6dd62c96a86b4fd171_hd.jpg" alt="avatar"></p><h2 id="3-Nash-Q-Learning算法"><a href="#3-Nash-Q-Learning算法" class="headerlink" title="3. Nash Q-Learning算法"></a>3. Nash Q-Learning算法</h2><p><strong>Condition</strong>: 多个玩家的一般和博弈(完全对抗博弈、完全合作博弈以及二者的混合博弈)<br><strong>Idea</strong>: 使用二次规划求解纳什均衡点<br><strong>Algorithm</strong>:<br><img src="https://pic4.zhimg.com/v2-5d50dc1f2ad874c22f10d5e796f64347_r.jpg" alt="avatar"><br>通过算法可以得知，在更新 Q 值时，取代了传统的期望奖励 V 函数，这里用了 Nash 函数进行了更新,需要观测其他所有智能体的动作 $a_i$ 与奖励值 $r_i$</p><h2 id="4-Friend-or-Foe-Q-Learning算法"><a href="#4-Friend-or-Foe-Q-Learning算法" class="headerlink" title="4. Friend-or-Foe Q-Learning算法"></a>4. Friend-or-Foe Q-Learning算法</h2><p><strong>Condition</strong>: 一个智能体i，将其他所有智能体分为两组，一组为i的friend帮助i一起最大化其奖励回报，另一组为i的foe对抗i并降低i的奖励回报，因此对每个智能体而言都有两组。这样一个n智能体的一般和博弈就转化为了一个两智能体的零和博弈<br><strong>Idea</strong>: 将剩余 agent 进行分组，在纳什均衡策略求解中，传统的所有 action 替换为了帮助自己的 action 和敌人的 action<br>Algorithm:<br><img src="https://pic1.zhimg.com/80/v2-2f4cff250568ca25853f1bc8e23e3b54_hd.jpg" alt="avatar"><br>为了更新 Q 值，每个智能体需要在每一步观测其他所有friend与foe的执行动作。</p><h2 id="5-WoLF-Policy-Hill-Climbing算法"><a href="#5-WoLF-Policy-Hill-Climbing算法" class="headerlink" title="5. WoLF Policy Hill-Climbing算法"></a>5. WoLF Policy Hill-Climbing算法</h2><p><strong>Condition</strong>: 每个智能体只用保存自己的动作来完成学习任务,个人认为为了避免前面三个算法带来的维度灾难问题，因为每个 agent 都需要存储所有 agent 的动作集。<br><strong>Idea</strong>:<br><strong>WolF</strong>:当智能体做的比期望值好的时候小心缓慢的调整参数，当智能体做的比期望值差的时候，加快步伐调整参数。<br><strong>PHC</strong>:一种单智能体在稳定环境下的一种学习算法。该算法的核心就是通常强化学习的思想，增大能够得到最大累积期望的动作的选取概率。该算法具有合理性，能够收敛到最优策略。其算法流程如下<br><strong>PHC Algorithm</strong>:<br><img src="https://pic4.zhimg.com/80/v2-8420ec197cb0516076725645a1359ab3_hd.jpg" alt="avatar"><br><strong>WOLF+PHC Algorithm</strong>:<br>通过PHC算法进行学习改进策略,收敛性没有得到证明。<br><img src="https://pic2.zhimg.com/80/v2-a549b9cfd895898e7a4cc74d7432ce55_hd.jpg" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> MARL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>痛苦的MARL(一)</title>
      <link href="/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%B8%80.html"/>
      <url>/%E7%97%9B%E8%8B%A6%E7%9A%84MARL-%E4%B8%80.html</url>
      
        <content type="html"><![CDATA[<h1 id="多智能体强化学习-一-基础知识与博弈"><a href="#多智能体强化学习-一-基础知识与博弈" class="headerlink" title="多智能体强化学习(一) 基础知识与博弈"></a>多智能体强化学习(一) 基础知识与博弈</h1><a id="more"></a><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><ol><li>多智能体通过和环境进行交互获取奖励值来学习改善自己的策略，其重点区别于单 agent 强化学习。</li><li>算法收敛性与每个 agent 的最优策略相关，其最优策略又与空间中其他的 agent 相关联。</li><li>联结动作:每个智能体当前动作组合而成的多智能体系统当前时刻的动作<br>$$<br>  A_t = [a_{1 ,t},a_{2 ,t},…,a_{n ,t}]^T<br>$$<br>其中$a_{i,t}$表示第 i 个智能体在时刻 t选取的动作<h2 id="2-博弈论"><a href="#2-博弈论" class="headerlink" title="2. 博弈论"></a>2. 博弈论</h2>由于多 agent 之间涉及到合作和竞争关系，引入博弈的概念。<h3 id="1-矩阵博弈"><a href="#1-矩阵博弈" class="headerlink" title="1. 矩阵博弈"></a>1. 矩阵博弈</h3>$$<br> (n,A_1,A_2,…,A_n,R_1,R_2,…,R_n)<br>$$<br>其中 n 为 agent 数量，$A_i$为第 i 个 agent 的 action 集合，$R_i$为奖励函数，其值与空间中所有的 agent 的 action 集都有关系<br> Target: 寻找纯策略或者混合策略 st 其收益虽大<h4 id="1-纳什均衡"><a href="#1-纳什均衡" class="headerlink" title="1. 纳什均衡"></a>1. 纳什均衡</h4>给定其他玩家继续采用纳什均衡策略而该玩家无法通过改变其自身策略获得更大回报的所有玩家策略的集合，即<br>$$<br> V_i(\pi_1^<em>,…,\pi_i^</em>,…,\pi_n^<em>) \geq V_i(\pi_1^</em>,…,\pi_i,…,\pi_n^*)<br>$$<br>其中 $V_i(.)$ 表示玩家 i 在给定玩家策略下的期望回报，其含义为$\sum$用户 i 在联合动作下所获得回报乘以每个用户采用纳什均衡策略下选择该动作的概率，<br>$\pi_i$表示玩家 i 在策略空间$\prod_i$中选择的任一策略(可以理解为概率)<h4 id="2-严格纳什均衡"><a href="#2-严格纳什均衡" class="headerlink" title="2. 严格纳什均衡"></a>2. 严格纳什均衡</h4>大于等于公式严格成立<h4 id="3-完全混合策略"><a href="#3-完全混合策略" class="headerlink" title="3. 完全混合策略"></a>3. 完全混合策略</h4>Definition: The strategy that agent choose specific action based on possibity of all actions.<br>Possibities of all actions ara more than 0 percentage.<br>在猜硬币博弈中，只要用户 50%的概率选择正面，50%的概率选择反面，才能获得最大收益。如果按照纯策略一直选择正面，则对方会知道并选择让自己一直收益的情况（一直正面或反面），无法达到最大收益<h4 id="4-纯策略"><a href="#4-纯策略" class="headerlink" title="4. 纯策略"></a>4. 纯策略</h4>在囚徒困境博弈中，agent 在任何情况下都选择同样的行为，也就是向警官坦白，这时候无论对方怎么选择，自己都是 reward 和都是最大的。<h3 id="2-agent在矩阵博弈中的纳什均衡"><a href="#2-agent在矩阵博弈中的纳什均衡" class="headerlink" title="2. agent在矩阵博弈中的纳什均衡"></a>2. agent在矩阵博弈中的纳什均衡</h3>其奖励矩阵为<br>$$<br> \begin{bmatrix}<br> r_{11}&amp;r_{12} \<br> r_{21}&amp;r_{22}<br> \end{bmatrix}<br>$$<br>其中行表示行 agent，列表式列 agent，其下角标表示行列 agent 所采取的动作联结。<h4 id="5-零和博弈"><a href="#5-零和博弈" class="headerlink" title="5. 零和博弈"></a>5. 零和博弈</h4>每玩一局游戏，都有一个玩家会赢而另一个玩家会输。两个玩家为完全竞争关系，<h4 id="6-一般和博弈"><a href="#6-一般和博弈" class="headerlink" title="6. 一般和博弈"></a>6. 一般和博弈</h4>任何类型的矩阵博弈<h3 id="3-多智能体强化学习策略"><a href="#3-多智能体强化学习策略" class="headerlink" title="3. 多智能体强化学习策略"></a>3. 多智能体强化学习策略</h3>引入他妈的随机博弈：多智能体多个状态，是马尔科夫决策过程和矩阵博弈的过程。</li></ol>]]></content>
      
      
      <categories>
          
          <category> MARL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无声告白</title>
      <link href="/%E6%97%A0%E5%A3%B0%E5%91%8A%E7%99%BD.html"/>
      <url>/%E6%97%A0%E5%A3%B0%E5%91%8A%E7%99%BD.html</url>
      
        <content type="html"><![CDATA[<p>别让人生从你身旁溜走<br>断断续续看了将近一个月，最后还是在图书馆完成了本书的阅读。<a id="more"></a>本怀着期待的心情，告诉她所有的故事的情节，但当我接起电话，才发现，我很难去梳理出一条简单的逻辑线给她讲清楚所有的故事梗概，或许，她永远都不会理解吧。</p><p>我认为书里描绘了两个重点，一个是相同，而另一个，是不同。</p><p>詹姆斯，作为第一批到达美国的中国人，皮肤，眼睛的颜色，服饰都与当地人格格不入，而且詹姆斯的父母都是蓝领，干着詹姆斯不愿提及的工作。一心想要寻求“相同”的詹姆斯努力学习，教育孩子一定要融入集体，找到小伙伴，可终其一生，还逃不过一句：中国佬找不到中国了。</p><p>玛丽琳是美国出生的正牌美国人，接受着相同的学校教育，家庭教育。从小就被母亲教育要做好饭，照顾好未来丈夫，孩子的她内心深处其实是排斥这些东西的。她想要获得自己的生活，不愿成为人们眼中相同的女人。即使是有了孩子，她也愿意远离孩子和丈夫，为了完成自己的梦想。</p><p>就是这么两个人生道路完全不同的人，走到了一起。或许是詹姆斯想要寻求融入，而玛丽琳想要寻求不同罢了。冥冥中，有些事情就已开始改变。他们有三个孩子，内斯，莉迪亚和汉娜。作为家里的大女儿，莉迪亚寄托了母亲太多的期待，即使是违背了自己的意愿，当母亲从离家出走到回到家的那一刻，莉迪亚知道了，自己一定要听母亲的，为了她不再离开这个家。慢慢的，莉迪亚身上的担子越来越多，生物，物理，母亲根本没有了解真正的莉迪亚，只是在心中构想了一个自己希望的莉迪亚罢了。当詹姆斯知道了这一切有些奇怪并告诉莉迪亚要融入集体的时候，一切都晚了。由于注意力的转移，身为老大的内斯可以沉浸在自己的世界中，即使这个世界并没有被父母所关心。他明白这个家庭的问题并一心想要逃离，但他还是爱莉迪亚的，了解她，照顾她。但，当内斯去了哈佛，没有了家庭的羁绊，他就像破茧而出的蝴蝶，不再回头看望自己遗留下的东西，而是展开翅膀迎接新的生活。作为家中唯一了解莉迪亚的人，他走了。莉迪亚没有了依靠，她想要解脱，想要逃离，当她跃入水中，现实的世界正远离她的时候，她找到了真正的归宿。</p><p>本书无声告白，乍一看还以为真的是告白。Everything I never told you是本书的原名。莉迪亚自始至终都没有告诉父母她真正想要的，一味地答应毁了她的一生。谁不是这样呢，人总是充满幻想，可以以后活成自己想要的模样，但现实是，绝大部分都成为了别人眼中的“相同”。遵循自己内心的想法真的很难，但或许当你想着，人死了，总要留下点什么的时候，你或许就会多一点在意自己的想法了吧。</p><p>以上这些，或许就是我想对你说的，但机会已经过去了，重新提起未免有些突兀，当然，我也不是很想分享给你，因为你不会去理会，或许我这辈子，只能和自己去分享读过的书了吧。对你，我真的不知道该怎么办，真的。</p><p>和莉迪亚一样，他们没有真正的朋友。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>March 26, 2019</title>
      <link href="/March-26-2019.html"/>
      <url>/March-26-2019.html</url>
      
        <content type="html"><![CDATA[<p>二姨，我又梦见你了，好像是看了伊藤润二的视频，人死后很可以通过某种仪式让你的灵魂活在世界中，你就是这样回到我们身边的，虽然看起来很不真实，但我又可以在你的身边了。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的梦 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>March 18, 2019</title>
      <link href="/March-18-2019.html"/>
      <url>/March-18-2019.html</url>
      
        <content type="html"><![CDATA[<p>寻找，找寻，生命，相关，起点</p><a id="more"></a><p>二姨，咱们又见面了，可是你这次真的，话好少。</p><p>我和老嘟在你设计的密室里面，需要寻找4个16进制数，但我们太笨了，怎么都找不到，最后你到了我们这里，但场景突然变了，我看到了姥爷的床头柜，你就坐在床头柜旁的凳子上，当我翻找柜子里面的东西的时候，你给我说，提示不在里面。很遗憾，我没有看你的脸，不知道你老了没有，但你的声音还是那么好听。梦醒了，我能记住的几个词汇，就是 寻找，找寻，生命，相关，起点。不知道为什么，梦里没有看到童童，是不是看到她，你又开哭了。在那边一个人生活挺苦的吧，但你还是要开心，因为童童生的长大了，给老嘟说了那么多道理，学习的，生活的。其中最令我感动的一句，是她说，你不要像姐姐一样，初中不好好学习，上了一个不好的高中，你要好好学，像哥哥一样，考一个好高中。你在那边听到这句话一定很欣慰吧，童童长大了，会照顾好自己的，你放心好了，这次就聊到这里吧，我要继续睡了。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的梦 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Dec 15, 2018</title>
      <link href="/Dec-15-2018.html"/>
      <url>/Dec-15-2018.html</url>
      
        <content type="html"><![CDATA[<p>太美好了…美好的我想哭。</p><p>仿佛这个梦…从我入睡…就开始了…<a id="more"></a>一直到…她说：咱们要做一辈子的好兄弟啊。现在8:27，我醒了，一切又回到了现实。</p><p>梦的原型，很像我和我前女友的故事。梦里的那个女孩，好想现实中的确存在，而且面部轮廓那么清晰，我是那么熟悉。她有男朋友的，但从梦的开始，我就没有见到他的男朋友。之前听人说，所有人都不记得梦是怎么开始的，我只记得，梦是在一间教室开始的，她坐在我后面，那堂客课，因为老师的封建迷信，我和老师吵了起来（由于梦里的元素实在太多了，我只能挑重要的元素去讲）后来不知怎么的，下课了，我就和那个女生，一块走了出来，我还记得那一天，我们去了星巴克，去了很多吃的地方，但每一次，都是我去找的她，仿佛她才是目的地，而我，只是一个奔跑者，而且每次都是我看着她吃，我一口也没有吃下去。我记得最清楚的一个桥段，是我们去吃串，店不大，在二楼，一楼是健身器材，同样是出现在我生命里的元素。我记得很清楚，她带了她两个朋友，而她两个朋友都误以为，我是她的男朋友，而她也不慌不忙地解释，连笑容都好好看。那一天过得好快，从一家店面出来，天已经黑了，我说，我送你回去吧，之后在路边扫了一辆电动车（校园里共享电动车的元素），她坐在后面，我带着她，当时的我，虽说不想和她处成兄弟，但她有男朋友。我的初恋，我也是作为第三者，但在现实生活中，我最终，追到了那个女生，但在梦里，是那个女生先开的口：咱们要做一辈子的好兄弟啊。我很清楚的记得，当时的我，骑着电动车，一句话也说不出来，哽咽着，我多希望我身边的那个人，是你。对不起，是我多想了。我醒了。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的梦 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Dec 27, 2017</title>
      <link href="/Dec-27-2017.html"/>
      <url>/Dec-27-2017.html</url>
      
        <content type="html"><![CDATA[<p>昨天在梦里，梦见姥娘因为太瘦，营养不良而双目失明，<a id="more"></a>我坐在桌前，哭了，或许是梦境太过于真实，哭醒了泪还是止不住。我坐了起来，用毛巾擦擦泪，但再也睡不着了。</p><p>这一年经历了太多…如意的…不顺的…生死离别也只不过是半个星期的事。希望姥娘能多吃点肉，别再那么瘦了，希望远方的你，也能照顾好自己，累了就蹲下来给自己一个大大的拥抱，告诉自己我还行。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的梦 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Dec 6, 2017</title>
      <link href="/Dec-6-2017.html"/>
      <url>/Dec-6-2017.html</url>
      
        <content type="html"><![CDATA[<p>我喜欢你是寂静的，仿佛你消失了一样，<a id="more"></a><br>你从远处聆听我，我的声音却无法触及你。<br>好像你的双眼已经飞离远去，如同一个吻，封缄了你的嘴。<br>如同所有的事物充满了我的灵魂，<br>你 从所有的事物中浮现，充满了我的灵魂。<br>你像我的灵魂，一只梦的蝴蝶。你如同忧郁这个词。<br>我喜欢你是寂静的，好像你已远去。<br>你听起来像在悲叹，一只如鸽悲鸣的蝴蝶。<br>你从远处聆听我，我的声音无法触及你：<br>你让我在你的沉默中安静无声。<br>并且让我借你的沉默与你说话，<br>你的沉默明亮如灯，简单如指环，<br>你就像黑夜，拥有寂寞与群星。<br>你的沉默就是星星的沉默，遥远而明亮。<br>我喜欢你是寂静的，仿佛你消失了一样，<br>遥远而且哀伤，仿佛你   已经死了。<br>彼时，一个字，一个微笑，已经足够。<br>而我会觉得幸福，因那不是真的而觉得幸福。</p>]]></content>
      
      
      <categories>
          
          <category> 旧的梦 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
